{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b450e5ea065b4be697cd384496e64a56","deepnote_cell_type":"text-cell-h2"},"source":"## CH 16. Natural Language Processing with RNNs and Attention","block_group":"3bb3229171224bf4a912f344819a2581"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7f5f24e6f57540fb9d47eacd10e1399b","deepnote_cell_type":"text-cell-h3"},"source":"### Generating Shakespearean Text Using a Character RNN","block_group":"037ad657684d473eadbf196051022c93"},{"cell_type":"code","metadata":{"source_hash":"40c9872b","execution_start":1744013046210,"execution_millis":4702,"execution_context_id":"11b63aa6-78ed-49a4-9daa-6488b0b51636","cell_id":"c6ac93e9ae06448e9780013abc18d9f1","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\ndef to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices(sequence)\n    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n    ds = ds.batch(batch_size)\n    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n\ndef next_char(text, temperature=1):\n    y_proba = shakespeare_model.predict([text])[0, -1:]\n    rescaled_logits = tf.math.log(y_proba) / temperature\n    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n    return text_vec_layer.get_vocabulary()[char_id +2]\n\ndef extend_text(text, n_chars=50, temperature=1):\n    for _ in range(n_chars):\n        text += next_char(text, temperature)\n    return text\n\nshakespeare_url = \"http://homl.info/shakespeare\"\nfilepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n\nwith open(filepath) as f:\n    shakespeare_text = f.read()\n\ntext_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n\ntext_vec_layer.adapt([shakespeare_text])\nencoded = text_vec_layer([shakespeare_text])[0]\n\nencoded -= 2\nn_tokens = text_vec_layer.vocabulary_size() - 2\n\nlength = 100\ntf.random.set_seed(42)\n\ntrain_set = to_dataset(encoded[:1_000_000], length, shuffle=True, seed=42)\nvalid_set = to_dataset(encoded[1_000_000:1_000_000 + 60_000], length)\ntest_set = to_dataset(encoded[1_000_000 + 60_000:], length)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n    tf.keras.layers.GRU(128, return_sequences=True),\n    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n])\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n\nmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\n    \"shakespeare_rnn.h5\", \n    monitor=\"val_accuracy\", \n    best_only=True\n)\n\n# history = model.fit(train_set, epochs=10, validation_data=valid_set, callbacks=[model_ckpt])","block_group":"c6ac93e9ae06448e9780013abc18d9f1","execution_count":1,"outputs":[{"name":"stderr","text":"2025-04-07 08:04:06.833576: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-07 08:04:06.886372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-07 08:04:06.886463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-07 08:04:06.887769: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-07 08:04:06.893825: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-07 08:04:06.894905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-07 08:04:08.223235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nDownloading data from http://homl.info/shakespeare\n","output_type":"stream"},{"output_type":"error","ename":"Exception","evalue":"URL fetch failure on http://homl.info/shakespeare: 503 -- Unavailable, the server is paused.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:347\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:85\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/usr/local/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Unavailable, the server is paused.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m     23\u001b[0m shakespeare_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://homl.info/shakespeare\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshakespeare.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshakespeare_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m     shakespeare_text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:349\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    347\u001b[0m     urlretrieve(origin, fpath, DLProgbar())\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39merrno, e\u001b[38;5;241m.\u001b[39mreason))\n","\u001b[0;31mException\u001b[0m: URL fetch failure on http://homl.info/shakespeare: 503 -- Unavailable, the server is paused."]}],"outputs_reference":"s3:deepnote-cell-outputs-production/7755303b-c595-4b7c-ac5f-c03d4284b593","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f89d631854fb4a79b05519202b5df6dd","deepnote_cell_type":"text-cell-h3"},"source":"### Sentiment Analysis for IMDb Reviews","block_group":"306bc25f1dd34c7091625e9df600d20c"},{"cell_type":"code","metadata":{"source_hash":"576acd71","execution_start":1743560494602,"execution_millis":810078,"execution_context_id":"9d077cf6-a108-409d-b452-5e04a0c2229d","deepnote_to_be_reexecuted":true,"cell_id":"ced236c7fad940ecaed76d91e6c552e1","deepnote_cell_type":"code"},"source":"!pip install tensorflow_datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nraw_train_set, raw_valid_set, raw_test_set = tfds.load(\n    name=\"imdb_reviews\",\n    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n    as_supervised=True\n)\ntf.random.set_seed(42)\ntrain_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\nvalid_set = raw_valid_set.batch(32).prefetch(1)\ntest_set = raw_test_set.batch(32).prefetch(1)\n\nvocab_size = 1000\ntext_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\ntext_vec_layer.adapt(train_set.map(lambda text, _: text))\n\nembed_size = 128\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(\n    loss=\"binary_crossentropy\", \n    optimizer=\"nadam\", \n    metrics=[\"accuracy\"]\n)\nhistory = model.fit(train_set, epochs=2, validation_data=valid_set)","block_group":"199c5caebaf644119c0317a6e1214fb8","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow_datasets\n  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting etils[edc,enp,epath,epy,etree]>=1.6.0\n  Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.2)\nRequirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.25.6)\nCollecting tensorflow-metadata\n  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\nCollecting immutabledict\n  Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\nCollecting toml\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: absl-py in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\nCollecting promise\n  Downloading promise-2.3.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: psutil in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (6.0.0)\nRequirement already satisfied: pyarrow in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (17.0.0)\nCollecting array_record>=0.5.0\n  Downloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\nCollecting dm-tree\n  Downloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nCollecting simple_parsing\n  Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\nCollecting einops\n  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing_extensions in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (4.12.2)\nCollecting zipp\n  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\nCollecting importlib_resources\n  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (2024.6.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\nRequirement already satisfied: attrs>=18.2.0 in /root/venv/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\nRequirement already satisfied: six in /root/venv/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\nCollecting docstring-parser<1.0,>=0.15\n  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nCollecting protobuf>=3.20\n  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: promise\n  Building wheel for promise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=5b6e18b86b9f3178a021d3476692c917e31b2b1e430c61885cd42f3d6f9c53b2\n  Stored in directory: /root/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\nSuccessfully built promise\nInstalling collected packages: zipp, toml, protobuf, promise, importlib_resources, immutabledict, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, array_record, tensorflow_datasets\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.25.6\n    Uninstalling protobuf-4.25.6:\n      Successfully uninstalled protobuf-4.25.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngrpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed array_record-0.7.1 dm-tree-0.1.9 docstring-parser-0.16 einops-0.8.1 etils-1.12.2 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 protobuf-3.20.3 simple_parsing-0.1.7 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.8 toml-0.10.2 zipp-3.21.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n2025-04-02 02:21:43.368149: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-02 02:21:43.401284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-02 02:21:43.401533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-02 02:21:43.402679: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-02 02:21:43.408829: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-02 02:21:43.410230: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-02 02:21:44.594984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nWARNING:absl:Variant folder /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0 has no dataset_info.json\n/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\nDl Completed...: 0 url [00:00, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Size...:   0%|          | 0/80 [00:00<?, ? MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Size...:   5%|▌         | 4/80 [00:02<01:35,  1.26s/ MiB]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Size...:  19%|█▉        | 15/80 [00:03<00:28,  2.29 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Size...:  48%|████▊     | 38/80 [00:04<00:07,  5.76 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Size...:  98%|█████████▊| 78/80 [00:05<00:00, 11.87 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...: 100%|██████████| 1/1 [00:05<00:00,  5.57s/ url]\nDl Size...: 100%|██████████| 80/80 [00:05<00:00, 14.34 MiB/s]\nDl Completed...: 100%|██████████| 1/1 [00:05<00:00,  5.58s/ url]\nGenerating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]\nGenerating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating train examples...: 1 examples [00:01,  1.93s/ examples]\u001b[A\nGenerating train examples...: 7411 examples [00:02, 3154.48 examples/s]\u001b[A\nGenerating train examples...: 15097 examples [00:03, 4867.87 examples/s]\u001b[A\nGenerating train examples...: 22816 examples [00:04, 5867.50 examples/s]\u001b[A\n                                                                        \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-train.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  33%|███▎      | 1/3 [00:08<00:16,  8.26s/ splits]\nGenerating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating test examples...: 4437 examples [00:01, 4436.79 examples/s]\u001b[A\nGenerating test examples...: 11714 examples [00:02, 6107.21 examples/s]\u001b[A\nGenerating test examples...: 19318 examples [00:03, 6790.60 examples/s]\u001b[A\n                                                                       \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-test.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  67%|██████▋   | 2/3 [00:16<00:08,  8.38s/ splits]\nGenerating unsupervised examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating unsupervised examples...: 1 examples [00:03,  3.31s/ examples]\u001b[A\nGenerating unsupervised examples...: 6163 examples [00:04, 1858.53 examples/s]\u001b[A\nGenerating unsupervised examples...: 13529 examples [00:05, 3516.72 examples/s]\u001b[A\nGenerating unsupervised examples...: 20957 examples [00:06, 4693.03 examples/s]\u001b[A\nGenerating unsupervised examples...: 28846 examples [00:07, 5653.36 examples/s]\u001b[A\nGenerating unsupervised examples...: 36576 examples [00:08, 6276.97 examples/s]\u001b[A\nGenerating unsupervised examples...: 44181 examples [00:09, 6675.54 examples/s]\u001b[A\n                                                                               \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-unsupervised.tfrecord*...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\nEpoch 1/2\n704/704 [==============================] - 385s 542ms/step - loss: 0.5561 - accuracy: 0.7058 - val_loss: 0.4643 - val_accuracy: 0.7872\nEpoch 2/2\n704/704 [==============================] - 378s 537ms/step - loss: 0.4939 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7776\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/db3b5d25-3355-4597-97ba-e96c73c2cb6e","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"33ae4a1cd7c648dd87ca29b1920446c0","deepnote_cell_type":"text-cell-h3"},"source":"### An Encoder–Decoder Network for Neural Machine\r Translation","block_group":"66ecf12ac9e0449ba8d171f25273e37d"},{"cell_type":"code","metadata":{"source_hash":"32564dc3","execution_start":1743993554553,"execution_millis":2552642,"execution_context_id":"67081a2d-045b-4b17-a688-c600975aabe1","cell_id":"4739a860696140e8bf0b2f48642690e1","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\nfrom pathlib import Path\n\nurl = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\npath = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, extract=True, cache_dir=\".\")\ntext = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()\n\ntext = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\npairs = [line.split(\"\\t\") for line in text.splitlines()]\nnp.random.seed(42)\nnp.random.shuffle(pairs)\nsentences_en, sentences_es = zip(*pairs)\n\nvocab_size =1000\nmax_length = 50\ntext_vec_layer_en = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_es = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_en.adapt(sentences_en)\ntext_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n\nX_train = tf.constant(sentences_en[:100_000])\nX_valid = tf.constant(sentences_en[100_000:])\nX_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\nX_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\nY_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]]).numpy()\nY_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]]).numpy()\n\nencoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\ndecoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n\nembed_size = 128\nencoder_input_ids = text_vec_layer_en(encoder_inputs)\ndecoder_input_ids = text_vec_layer_es(decoder_inputs)\nencoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\ndecoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\nencoder_embeddings = encoder_embedding_layer(encoder_input_ids)\ndecoder_embeddings = decoder_embedding_layer(decoder_input_ids)\n\nencoder = tf.keras.layers.LSTM(512, return_state=True)\nencoder_outputs, *encoder_state = encoder(encoder_embeddings)\n\ndecoder = tf.keras.layers.LSTM(512, return_sequences=True)\ndecoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n\noutput_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\nY_proba = output_layer(decoder_outputs)\n\nmodel = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=Y_proba)\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\", \n    optimizer=\"nadam\", \n    metrics=[\"accuracy\"]\n)\n\nmodel.fit(\n    (X_train, X_train_dec),\n    Y_train,\n    epochs=1, \n    validation_data=((X_valid, X_valid_dec), Y_valid)\n)","block_group":"dfaa2d3c945144f6bd8383ba570f6912","execution_count":3,"outputs":[{"name":"stderr","text":"2025-04-07 02:39:14.674062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n3125/3125 [==============================] - 2533s 809ms/step - loss: 2.9537 - accuracy: 0.4203 - val_loss: 2.2046 - val_accuracy: 0.5200\n","output_type":"stream"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<keras.src.callbacks.History at 0x7fcd250caaa0>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/68cd1934-1cf9-4083-8352-b850967f47bf","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4653a8b6d4a24e74b96962809309c5d6","deepnote_cell_type":"text-cell-h3"},"source":"### Attention Is All You Need: The Original Transformer","block_group":"820b5cd96d564841a84a03b99da1023b"},{"cell_type":"code","metadata":{"source_hash":"4162789d","execution_start":1743998298777,"execution_millis":1261494,"execution_context_id":"6439d031-fc15-4897-869c-1566e804d6a5","cell_id":"68d5145fac9e4fd7accaf67cf85509bc","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\nfrom pathlib import Path\n\nurl = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\npath = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, extract=True, cache_dir=\".\")\ntext = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()\n\ntext = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\npairs = [line.split(\"\\t\") for line in text.splitlines()]\nnp.random.seed(42)\nnp.random.shuffle(pairs)\nsentences_en, sentences_es = zip(*pairs)\n\nvocab_size =1000\nmax_length = 50\ntext_vec_layer_en = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_es = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_en.adapt(sentences_en)\ntext_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n\nX_train = tf.constant(sentences_en[:100_000])\nX_valid = tf.constant(sentences_en[100_000:])\nX_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\nX_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\nY_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]]).numpy()\nY_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]]).numpy()\n\nencoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\ndecoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n\nembed_size = 128\nencoder_input_ids = text_vec_layer_en(encoder_inputs)\ndecoder_input_ids = text_vec_layer_es(decoder_inputs)\nencoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\ndecoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\nencoder_embeddings = encoder_embedding_layer(encoder_input_ids)\ndecoder_embeddings = decoder_embedding_layer(decoder_input_ids)\n\nmax_length = 50\nembed_size = 128\npos_embed_layer = tf.keras.layers.Embedding(max_length, embed_size)\nbatch_max_len_enc = tf.shape(encoder_embeddings)[1]\nencoder_in = encoder_embeddings + pos_embed_layer(tf.range(batch_max_len_enc))\nbatch_max_len_dec = tf.shape(decoder_embeddings)[1]\ndecoder_in = decoder_embeddings + pos_embed_layer(tf.range(batch_max_len_dec))\n\n# Build the encoder for transformer achitecture\nN = 2\nnum_heads = 2\ndropout_rate = 0.1\nn_units = 128\nencoder_pad_mask = tf.math.not_equal(encoder_input_ids, 0)[:, tf.newaxis]\nZ_enc = encoder_in\nembed_size = 128\n\nfor _ in range(N):\n    skip = Z_enc\n    attn_layer = tf.keras.layers.MultiHeadAttention(\n        num_heads=num_heads,\n        key_dim=embed_size,\n        dropout=dropout_rate\n    )\n    Z_enc = attn_layer(Z_enc, value=Z_enc, attention_mask=encoder_pad_mask)\n    Z_enc = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z_enc, skip]))\n    skip = Z_enc\n    Z_enc = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z_enc)\n    Z_enc = tf.keras.layers.Dense(embed_size)(Z_enc)\n    Z_enc = tf.keras.layers.Dropout(dropout_rate)(Z_enc)\n    Z_enc = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z_enc, skip]))\n\n# Build the decoder for transformer achitecture\ndecoder_pad_mask = tf.math.not_equal(decoder_input_ids, 0)[:, tf.newaxis]\ncausal_mask = tf.linalg.band_part(tf.ones((batch_max_len_dec, batch_max_len_dec), dtype=tf.bool), -1, 0)\n\nencoder_outputs = Z_enc\nZ_dec = decoder_in\nfor _ in range(N):\n    skip = Z_dec\n    attn_layer = tf.keras.layers.MultiHeadAttention(\n        num_heads=num_heads,\n        key_dim=embed_size,\n        dropout=dropout_rate\n    )\n    Z_dec = attn_layer(Z_dec, value=Z_enc, attention_mask=causal_mask & decoder_pad_mask)\n    Z_dec = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z_dec, skip]))\n    skip = Z_dec\n    attn_layer = tf.keras.layers.MultiHeadAttention(\n        num_heads=num_heads,\n        key_dim=embed_size,\n        dropout=dropout_rate\n    )\n    Z_dec = attn_layer(Z_dec, value=encoder_outputs, attention_mask=encoder_pad_mask)\n    Z_dec = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z_dec, skip]))\n    skip = Z_dec\n    Z_dec = tf.keras.layers.Dense(n_units, activation=\"relu\")(Z_dec)\n    Z_dec = tf.keras.layers.Dense(embed_size)(Z_dec)\n    Z_dec = tf.keras.layers.Dropout(dropout_rate)(Z_dec)\n    Z_dec = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z_dec, skip]))\n\nY_proba = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(Z_dec)\n\nmodel = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[Y_proba])\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\", \n    optimizer=\"nadam\", \n    metrics=[\"accuracy\"]\n)\n\nmodel.fit(\n    (X_train, X_train_dec),\n    Y_train,\n    epochs=1, \n    validation_data=((X_valid, X_valid_dec), Y_valid)\n)\n","block_group":"804aff9bd5f44cfa9e73e237f7ef317a","execution_count":3,"outputs":[{"name":"stdout","text":"3125/3125 [==============================] - 1210s 383ms/step - loss: 0.3306 - accuracy: 0.9346 - val_loss: 0.2145 - val_accuracy: 0.9493\n","output_type":"stream"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<keras.src.callbacks.History at 0x7f6670074910>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/7e3101ad-dccf-4c0d-98ca-4a0a3f050ef1","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"04515889ffd34f439ceea643a27d1de3","deepnote_cell_type":"text-cell-h3"},"source":"### Hugging Face’s Transformers Library","block_group":"09d8b8e1823344f9b1773b2a42a3b791"},{"cell_type":"code","metadata":{"source_hash":"415c36","execution_start":1744013795550,"execution_millis":6734,"execution_context_id":"11b63aa6-78ed-49a4-9daa-6488b0b51636","cell_id":"babb272a9a4a48b39db451583b156c49","deepnote_cell_type":"code"},"source":"!pip install --upgrade pip\n!pip install transformers\n!pip install torch\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")\nresult = classifier(\"I love you\")\nresult","block_group":"d74d8bb991df44349ccae79f08edcabb","execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (25.0.1)\nRequirement already satisfied: transformers in /root/venv/lib/python3.10/site-packages (4.51.0)\nRequirement already satisfied: filelock in /root/venv/lib/python3.10/site-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /root/venv/lib/python3.10/site-packages (from transformers) (0.30.1)\nRequirement already satisfied: numpy>=1.17 in /root/venv/lib/python3.10/site-packages (from transformers) (1.25.2)\nRequirement already satisfied: packaging>=20.0 in /root/venv/lib/python3.10/site-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /root/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /root/venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /root/venv/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /root/venv/lib/python3.10/site-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /root/venv/lib/python3.10/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /root/venv/lib/python3.10/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /toolkit-cache/0.2.13/python3.10/kernel-libs/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /root/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: torch in /root/venv/lib/python3.10/site-packages (2.6.0)\nRequirement already satisfied: filelock in /root/venv/lib/python3.10/site-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /root/venv/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /root/venv/lib/python3.10/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /root/venv/lib/python3.10/site-packages (from torch) (3.1.5)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.13/python3.10/kernel-libs/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/venv/lib/python3.10/site-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/venv/lib/python3.10/site-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/venv/lib/python3.10/site-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/venv/lib/python3.10/site-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /root/venv/lib/python3.10/site-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/venv/lib/python3.10/site-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/venv/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /root/venv/lib/python3.10/site-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /root/venv/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /root/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /root/venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n","output_type":"stream"},{"output_type":"error","ename":"RuntimeError","evalue":"Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'Backend' from 'torch._C._distributed_c10d' (unknown location)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/usr/local/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:49\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     37\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioClassificationPipeline\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatic_speech_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutomaticSpeechRecognitionPipeline\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_end_docstrings, is_torch_available, is_torchaudio_available, logging\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline, build_pipeline_init_args\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:41\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/distributed/tensor/__init__.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m  \u001b[38;5;66;03m# force import all built-in dtensor ops\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh, init_device_mesh  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/distributed/tensor/_ops/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_embedding_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/distributed/tensor/_ops/_conv_ops.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dtensor_spec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTensorSpec, TensorMeta\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_op_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpSchema, OutputSharding\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/distributed/tensor/_dtensor_spec.py:5\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplacement_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Partial,\n\u001b[1;32m      8\u001b[0m     Placement,\n\u001b[1;32m      9\u001b[0m     Replicate,\n\u001b[1;32m     10\u001b[0m     Shard,\n\u001b[1;32m     11\u001b[0m )\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/distributed/device_mesh.py:39\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distributed_c10d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Backend \u001b[38;5;28;01mas\u001b[39;00m C10dBackend\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_c10d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m         _find_pg_by_ranks_and_tag,\n\u001b[1;32m     42\u001b[0m         _get_default_group,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         split_group,\n\u001b[1;32m     53\u001b[0m     )\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Backend' from 'torch._C._distributed_c10d' (unknown location)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install torch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m classifier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI love you\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'Backend' from 'torch._C._distributed_c10d' (unknown location)"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/270ccc27-d4f4-4c6d-9eeb-74999bd77fee","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=968d3c27-50e7-4d42-bdd9-442f6904c1c2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2025-04-07T08:35:57.610Z"},"deepnote_notebook_id":"7f8ef00bdf8a44e1b5f6bd6faece8b7d"}}