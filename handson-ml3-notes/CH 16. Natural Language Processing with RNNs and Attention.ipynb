{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b450e5ea065b4be697cd384496e64a56","deepnote_cell_type":"text-cell-h2"},"source":"## CH 16. Natural Language Processing with RNNs and Attention","block_group":"3bb3229171224bf4a912f344819a2581"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7f5f24e6f57540fb9d47eacd10e1399b","deepnote_cell_type":"text-cell-h3"},"source":"### Generating Shakespearean Text Using a Character RNN","block_group":"037ad657684d473eadbf196051022c93"},{"cell_type":"code","metadata":{"source_hash":"79b64cbe","execution_start":1743494159273,"execution_millis":6148,"execution_context_id":"5fc3a151-62d5-4ac4-b680-84a4a077a1ba","cell_id":"c6ac93e9ae06448e9780013abc18d9f1","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\ndef to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices(sequence)\n    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n    ds = ds.batch(batch_size)\n    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n\ndef next_char(text, temperature=1):\n    y_proba = shakespeare_model.predict([text])[0, -1:]\n    rescaled_logits = tf.math.log(y_proba) / temperature\n    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n    return text_vec_layer.get_vocabulary()[char_id +2]\n\ndef extend_text(text, n_chars=50, temperature=1):\n    for _ in range(n_chars):\n        text += next_char(text, temperature)\n    return text\n\nshakespeare_url = \"http://homl.info/shakespeare\"\nfilepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n\nwith open(filepath) as f:\n    shakespeare_text = f.read()\n\ntext_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n\ntext_vec_layer.adapt([shakespeare_text])\nencoded = text_vec_layer([shakespeare_text])[0]\n\nencoded -= 2\nn_tokens = text_vec_layer.vocabulary_size() - 2\n\nlength = 100\ntf.random.set_seed(42)\n\ntrain_set = to_dataset(encoded[:1_000_000], length, shuffle=True, seed=42)\nvalid_set = to_dataset(encoded[1_000_000:1_000_000 + 60_000], length)\ntest_set = to_dataset(encoded[1_000_000 + 60_000:], length)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n    tf.keras.layers.GRU(128, return_sequences=True),\n    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n])\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n\nmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\n    \"shakespeare_rnn.h5\", \n    monitor=\"val_accuracy\", \n    best_only=True\n)\n\n# history = model.fit(train_set, epochs=10, validation_data=valid_set, callbacks=[model_ckpt])","block_group":"c6ac93e9ae06448e9780013abc18d9f1","execution_count":1,"outputs":[{"name":"stderr","text":"2025-04-01 07:55:59.653135: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-01 07:55:59.705849: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-01 07:55:59.705936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-01 07:55:59.707434: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-01 07:55:59.717854: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-01 07:55:59.718867: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-01 07:56:01.628555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nDownloading data from http://homl.info/shakespeare\n1115394/1115394 [==============================] - 0s 0us/step\n","output_type":"stream"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/d1cf6c44-854f-445f-8469-32517264e44d","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f89d631854fb4a79b05519202b5df6dd","deepnote_cell_type":"text-cell-h3"},"source":"### Sentiment Analysis for IMDb Reviews","block_group":"306bc25f1dd34c7091625e9df600d20c"},{"cell_type":"code","metadata":{"source_hash":"576acd71","execution_start":1743560494602,"execution_millis":810078,"execution_context_id":"9d077cf6-a108-409d-b452-5e04a0c2229d","cell_id":"ced236c7fad940ecaed76d91e6c552e1","deepnote_cell_type":"code"},"source":"!pip install tensorflow_datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nraw_train_set, raw_valid_set, raw_test_set = tfds.load(\n    name=\"imdb_reviews\",\n    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n    as_supervised=True\n)\ntf.random.set_seed(42)\ntrain_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\nvalid_set = raw_valid_set.batch(32).prefetch(1)\ntest_set = raw_test_set.batch(32).prefetch(1)\n\nvocab_size = 1000\ntext_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\ntext_vec_layer.adapt(train_set.map(lambda text, _: text))\n\nembed_size = 128\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(\n    loss=\"binary_crossentropy\", \n    optimizer=\"nadam\", \n    metrics=[\"accuracy\"]\n)\nhistory = model.fit(train_set, epochs=2, validation_data=valid_set)","block_group":"199c5caebaf644119c0317a6e1214fb8","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow_datasets\n  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting etils[edc,enp,epath,epy,etree]>=1.6.0\n  Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.2)\nRequirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.25.6)\nCollecting tensorflow-metadata\n  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\nCollecting immutabledict\n  Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\nCollecting toml\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: absl-py in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\nCollecting promise\n  Downloading promise-2.3.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: psutil in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (6.0.0)\nRequirement already satisfied: pyarrow in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (17.0.0)\nCollecting array_record>=0.5.0\n  Downloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\nCollecting dm-tree\n  Downloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nCollecting simple_parsing\n  Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\nCollecting einops\n  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing_extensions in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (4.12.2)\nCollecting zipp\n  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\nCollecting importlib_resources\n  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.12/python3.10/kernel-libs/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (2024.6.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\nRequirement already satisfied: attrs>=18.2.0 in /root/venv/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\nRequirement already satisfied: six in /root/venv/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\nCollecting docstring-parser<1.0,>=0.15\n  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nCollecting protobuf>=3.20\n  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: promise\n  Building wheel for promise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=5b6e18b86b9f3178a021d3476692c917e31b2b1e430c61885cd42f3d6f9c53b2\n  Stored in directory: /root/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\nSuccessfully built promise\nInstalling collected packages: zipp, toml, protobuf, promise, importlib_resources, immutabledict, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, array_record, tensorflow_datasets\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.25.6\n    Uninstalling protobuf-4.25.6:\n      Successfully uninstalled protobuf-4.25.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngrpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed array_record-0.7.1 dm-tree-0.1.9 docstring-parser-0.16 einops-0.8.1 etils-1.12.2 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 protobuf-3.20.3 simple_parsing-0.1.7 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.8 toml-0.10.2 zipp-3.21.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n2025-04-02 02:21:43.368149: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-02 02:21:43.401284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-02 02:21:43.401533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-02 02:21:43.402679: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-02 02:21:43.408829: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-02 02:21:43.410230: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-02 02:21:44.594984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nWARNING:absl:Variant folder /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0 has no dataset_info.json\n/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\nDl Completed...: 0 url [00:00, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Size...:   0%|          | 0/80 [00:00<?, ? MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Size...:   5%|▌         | 4/80 [00:02<01:35,  1.26s/ MiB]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Size...:  19%|█▉        | 15/80 [00:03<00:28,  2.29 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Size...:  48%|████▊     | 38/80 [00:04<00:07,  5.76 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Size...:  98%|█████████▊| 78/80 [00:05<00:00, 11.87 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...: 100%|██████████| 1/1 [00:05<00:00,  5.57s/ url]\nDl Size...: 100%|██████████| 80/80 [00:05<00:00, 14.34 MiB/s]\nDl Completed...: 100%|██████████| 1/1 [00:05<00:00,  5.58s/ url]\nGenerating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]\nGenerating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating train examples...: 1 examples [00:01,  1.93s/ examples]\u001b[A\nGenerating train examples...: 7411 examples [00:02, 3154.48 examples/s]\u001b[A\nGenerating train examples...: 15097 examples [00:03, 4867.87 examples/s]\u001b[A\nGenerating train examples...: 22816 examples [00:04, 5867.50 examples/s]\u001b[A\n                                                                        \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-train.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  33%|███▎      | 1/3 [00:08<00:16,  8.26s/ splits]\nGenerating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating test examples...: 4437 examples [00:01, 4436.79 examples/s]\u001b[A\nGenerating test examples...: 11714 examples [00:02, 6107.21 examples/s]\u001b[A\nGenerating test examples...: 19318 examples [00:03, 6790.60 examples/s]\u001b[A\n                                                                       \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-test.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  67%|██████▋   | 2/3 [00:16<00:08,  8.38s/ splits]\nGenerating unsupervised examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating unsupervised examples...: 1 examples [00:03,  3.31s/ examples]\u001b[A\nGenerating unsupervised examples...: 6163 examples [00:04, 1858.53 examples/s]\u001b[A\nGenerating unsupervised examples...: 13529 examples [00:05, 3516.72 examples/s]\u001b[A\nGenerating unsupervised examples...: 20957 examples [00:06, 4693.03 examples/s]\u001b[A\nGenerating unsupervised examples...: 28846 examples [00:07, 5653.36 examples/s]\u001b[A\nGenerating unsupervised examples...: 36576 examples [00:08, 6276.97 examples/s]\u001b[A\nGenerating unsupervised examples...: 44181 examples [00:09, 6675.54 examples/s]\u001b[A\n                                                                               \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.RN442G_1.0.0/imdb_reviews-unsupervised.tfrecord*...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\nEpoch 1/2\n704/704 [==============================] - 385s 542ms/step - loss: 0.5561 - accuracy: 0.7058 - val_loss: 0.4643 - val_accuracy: 0.7872\nEpoch 2/2\n704/704 [==============================] - 378s 537ms/step - loss: 0.4939 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7776\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/db3b5d25-3355-4597-97ba-e96c73c2cb6e","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"33ae4a1cd7c648dd87ca29b1920446c0","deepnote_cell_type":"text-cell-h3"},"source":"### An Encoder–Decoder Network for Neural Machine\r Translation","block_group":"66ecf12ac9e0449ba8d171f25273e37d"},{"cell_type":"code","metadata":{"source_hash":"234bb9e6","execution_start":1743642797635,"execution_millis":10301747,"execution_context_id":"e2350ff6-383b-4e22-9d0e-e675529767ee","cell_id":"4739a860696140e8bf0b2f48642690e1","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\nfrom pathlib import Path\n\nurl = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\npath = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, extract=True, cache_dir=\".\")\ntext = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()\n\ntext = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\npairs = [line.split(\"\\t\") for line in text.splitlines()]\nnp.random.seed(42)\nnp.random.shuffle(pairs)\nsentences_en, sentences_es = zip(*pairs)\n\nvocab_size =1000\nmax_length = 50\ntext_vec_layer_en = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_es = tf.keras.layers.TextVectorization(\n    max_tokens=vocab_size, \n    output_sequence_length=max_length\n)\ntext_vec_layer_en.adapt(sentences_en)\ntext_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n\nX_train = tf.constant(sentences_en[:100_000])\nX_valid = tf.constant(sentences_en[100_000:])\nX_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\nX_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\nY_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]]).numpy()\nY_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]]).numpy()\n\nencoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\ndecoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n\nembed_size = 128\nencoder_input_ids = text_vec_layer_en(encoder_inputs)\ndecoder_input_ids = text_vec_layer_es(decoder_inputs)\nencoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\ndecoder_embedding_layer = tf.keras.layers.Embedding(\n    vocab_size, \n    embed_size,\n    mask_zero=True\n)\nencoder_embeddings = encoder_embedding_layer(encoder_input_ids)\ndecoder_embeddings = decoder_embedding_layer(decoder_input_ids)\n\nencoder = tf.keras.layers.LSTM(512, return_state=True)\nencoder_outputs, *encoder_state = encoder(encoder_embeddings)\n\ndecoder = tf.keras.layers.LSTM(512, return_sequences=True)\ndecoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n\noutput_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\nY_proba = output_layer(decoder_outputs)\n\nmodel = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=Y_proba)\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\", \n    optimizer=\"nadam\", \n    metrics=[\"accuracy\"]\n)\n\nmodel.fit(\n    (X_train, X_train_dec),\n    Y_train,\n    epochs=10, \n    validation_data=((X_valid, X_valid_dec), Y_valid)\n)","block_group":"dfaa2d3c945144f6bd8383ba570f6912","execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n3125/3125 [==============================] - 2510s 802ms/step - loss: 2.9386 - accuracy: 0.4235 - val_loss: 2.1963 - val_accuracy: 0.5172\nEpoch 2/10\n3125/3125 [==============================] - 2489s 796ms/step - loss: 1.8617 - accuracy: 0.5716 - val_loss: 1.6615 - val_accuracy: 0.6083\nEpoch 3/10\n3125/3125 [==============================] - 2486s 795ms/step - loss: 1.4403 - accuracy: 0.6474 - val_loss: 1.4328 - val_accuracy: 0.6515\nEpoch 4/10\n3125/3125 [==============================] - 2424s 776ms/step - loss: 1.2035 - accuracy: 0.6936 - val_loss: 1.3329 - val_accuracy: 0.6729\nEpoch 5/10\n 521/3125 [====>.........................] - ETA: 31:34 - loss: 1.0039 - accuracy: 0.7359","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 71\u001b[0m\n\u001b[1;32m     63\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[encoder_inputs, decoder_inputs], outputs\u001b[38;5;241m=\u001b[39mY_proba)\n\u001b[1;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     66\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     68\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_dec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid_dec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"outputs_reference":"s3:deepnote-cell-outputs-production/8c458535-8c38-4292-8945-8550b8894726","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4653a8b6d4a24e74b96962809309c5d6","deepnote_cell_type":"text-cell-h3"},"source":"### Attention Is All You Need: The Original Transforme","block_group":"820b5cd96d564841a84a03b99da1023b"},{"cell_type":"code","metadata":{"cell_id":"68d5145fac9e4fd7accaf67cf85509bc","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\n","block_group":"804aff9bd5f44cfa9e73e237f7ef317a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=968d3c27-50e7-4d42-bdd9-442f6904c1c2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"7f8ef00bdf8a44e1b5f6bd6faece8b7d"}}