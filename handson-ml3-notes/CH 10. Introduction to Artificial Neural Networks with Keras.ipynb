{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0883d7c07775422d989925ef372f23ee","deepnote_cell_type":"text-cell-h1"},"source":"# Introduction to Artificial Neural Networks with Keras","block_group":"f40ad0f30a894ca48b4fa873e41c1996"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d8b9740c1a0d43b395ab7a2c6ae8e463","deepnote_cell_type":"text-cell-h3"},"source":"### Regression MLPs with Scikit-Learn","block_group":"7b330178b3584da1b5ef552d3a538d2a"},{"cell_type":"code","metadata":{"source_hash":"a68abca1","execution_start":1741069300348,"execution_millis":12318,"execution_context_id":"997a7b8e-c976-46d6-be12-d7fa00382eb9","cell_id":"64a1f2a6a92e4b41ac5f6e8e15c4c700","deepnote_cell_type":"code"},"source":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nhousing = fetch_california_housing()\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full, random_state=42)\n\nmlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\npipeline = make_pipeline(StandardScaler(), mlp_reg)\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_valid)\nrmse = mean_squared_error(y_valid, y_pred, squared=False)\n\nprint(rmse)","block_group":"10f5950fb650468abf0fbd98eb3cdc72","execution_count":1,"outputs":[{"name":"stdout","text":"0.6193725725047629\n/root/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/009310f5-0a1f-41e4-9f6f-4fb1daaac070","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a0cabb1311024f74a495f4256cf57d9e","deepnote_cell_type":"text-cell-h3"},"source":"### Classification MLPs with Keras","block_group":"c6d6e63580254294ac86abad47655aa5"},{"cell_type":"code","metadata":{"source_hash":"615f254d","execution_start":1741072082292,"execution_millis":195379,"execution_context_id":"547cb16f-5512-451b-9c57-14af6f718a65","cell_id":"f6bede10b8c8423dbe3c38b5c3762b84","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\nfashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\nX_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\nX_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n\n# Preprocessing of data\nX_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n# MLPs with Keras\ntf.keras.utils.set_random_seed(42)\n# model = tf.keras.Sequential()\n# model.add(tf.keras.layers.Input(shape=[28,28]))\n# model.add(tf.keras.layers.Flatten())\n# model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n# model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=[28, 28]),\n    tf.keras.layers.Dense(300, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\n# model.summary()\n# model.layers\n\n# hidden1 = model.layers[1]\n# hidden1.name\n\n# weights, biases = hidden1.get_weights()\n# weights.shape\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer=\"sgd\",\n    metrics=[\"accuracy\"]\n)\n\nhistory = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n","block_group":"e581eff3d6854f48b5f63034abdd496f","execution_count":3,"outputs":[{"name":"stderr","text":"2025-03-04 07:08:02.604008: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-03-04 07:08:02.607607: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-04 07:08:02.642774: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-04 07:08:02.642895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-04 07:08:02.644339: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-04 07:08:02.652547: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-04 07:08:02.653536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-03-04 07:08:03.593417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 [==============================] - 0s 0us/step\nEpoch 1/30\n1719/1719 [==============================] - 7s 4ms/step - loss: 0.7239 - accuracy: 0.7616 - val_loss: 0.5026 - val_accuracy: 0.8298\nEpoch 2/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.4890 - accuracy: 0.8305 - val_loss: 0.4498 - val_accuracy: 0.8368\nEpoch 3/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.4419 - accuracy: 0.8441 - val_loss: 0.4220 - val_accuracy: 0.8548\nEpoch 4/30\n1719/1719 [==============================] - 7s 4ms/step - loss: 0.4164 - accuracy: 0.8541 - val_loss: 0.3934 - val_accuracy: 0.8608\nEpoch 5/30\n1719/1719 [==============================] - 7s 4ms/step - loss: 0.3955 - accuracy: 0.8613 - val_loss: 0.3903 - val_accuracy: 0.8606\nEpoch 6/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3789 - accuracy: 0.8666 - val_loss: 0.3918 - val_accuracy: 0.8642\nEpoch 7/30\n1719/1719 [==============================] - 7s 4ms/step - loss: 0.3663 - accuracy: 0.8697 - val_loss: 0.3662 - val_accuracy: 0.8692\nEpoch 8/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3549 - accuracy: 0.8745 - val_loss: 0.3749 - val_accuracy: 0.8618\nEpoch 9/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3444 - accuracy: 0.8778 - val_loss: 0.3471 - val_accuracy: 0.8734\nEpoch 10/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3341 - accuracy: 0.8808 - val_loss: 0.3490 - val_accuracy: 0.8738\nEpoch 11/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3254 - accuracy: 0.8827 - val_loss: 0.3685 - val_accuracy: 0.8654\nEpoch 12/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3172 - accuracy: 0.8866 - val_loss: 0.3490 - val_accuracy: 0.8728\nEpoch 13/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3097 - accuracy: 0.8895 - val_loss: 0.3285 - val_accuracy: 0.8818\nEpoch 14/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.3022 - accuracy: 0.8900 - val_loss: 0.3377 - val_accuracy: 0.8814\nEpoch 15/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2961 - accuracy: 0.8941 - val_loss: 0.3354 - val_accuracy: 0.8796\nEpoch 16/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2890 - accuracy: 0.8962 - val_loss: 0.3224 - val_accuracy: 0.8842\nEpoch 17/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2837 - accuracy: 0.8970 - val_loss: 0.3337 - val_accuracy: 0.8790\nEpoch 18/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2780 - accuracy: 0.9002 - val_loss: 0.3221 - val_accuracy: 0.8820\nEpoch 19/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2723 - accuracy: 0.9018 - val_loss: 0.3482 - val_accuracy: 0.8698\nEpoch 20/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2676 - accuracy: 0.9030 - val_loss: 0.3149 - val_accuracy: 0.8878\nEpoch 21/30\n1719/1719 [==============================] - 7s 4ms/step - loss: 0.2626 - accuracy: 0.9056 - val_loss: 0.3142 - val_accuracy: 0.8880\nEpoch 22/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2574 - accuracy: 0.9077 - val_loss: 0.3129 - val_accuracy: 0.8884\nEpoch 23/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2532 - accuracy: 0.9095 - val_loss: 0.3423 - val_accuracy: 0.8764\nEpoch 24/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2478 - accuracy: 0.9111 - val_loss: 0.3177 - val_accuracy: 0.8834\nEpoch 25/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2437 - accuracy: 0.9121 - val_loss: 0.3158 - val_accuracy: 0.8840\nEpoch 26/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2400 - accuracy: 0.9150 - val_loss: 0.3123 - val_accuracy: 0.8882\nEpoch 27/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2351 - accuracy: 0.9146 - val_loss: 0.3183 - val_accuracy: 0.8880\nEpoch 28/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2318 - accuracy: 0.9171 - val_loss: 0.3065 - val_accuracy: 0.8926\nEpoch 29/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2283 - accuracy: 0.9178 - val_loss: 0.3187 - val_accuracy: 0.8828\nEpoch 30/30\n1719/1719 [==============================] - 6s 4ms/step - loss: 0.2246 - accuracy: 0.9202 - val_loss: 0.3035 - val_accuracy: 0.8924\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/d03832a7-5491-47e4-ae6c-598189c3d80b","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"cca5159a7cf04c2cbd773bb4cf1bba38","deepnote_cell_type":"text-cell-p"},"source":"Using model to do prediction for new instances: ","block_group":"e46ac8b55c014ae1a9661eddc2d580ec"},{"cell_type":"code","metadata":{"source_hash":"fe84ce51","execution_start":1741073950756,"execution_millis":727,"execution_context_id":"547cb16f-5512-451b-9c57-14af6f718a65","cell_id":"c23bc0defe954648bfd025123fa34625","deepnote_cell_type":"code"},"source":"model.evaluate(X_test, y_test)\n\nX_new = X_test[:3]\ny_proba = model.predict(X_new)\ny_proba.round(2)\n\ny_proba_index = y_proba.argmax(axis=-1)\ny_proba_index\n\ny_new = y_test[:3]\ny_new","block_group":"81c2600014b84767bc64ccb667f83b12","execution_count":11,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8844\n1/1 [==============================] - 0s 14ms/step\n","output_type":"stream"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([9, 2, 1], dtype=uint8)"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/9c4088ee-cf25-4124-aa25-f3713b2b7284","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"84fbf92a03904851ac91ce826a8bdafb","deepnote_cell_type":"text-cell-h3"},"source":"### Regression MLPs with Keras","block_group":"63985b2d9da048898f4f05766df1c2db"},{"cell_type":"code","metadata":{"source_hash":"1fd69fc4","execution_start":1741076729048,"execution_millis":18569,"execution_context_id":"547cb16f-5512-451b-9c57-14af6f718a65","cell_id":"4b1b6595a5404c3e8b0c2db33f81e858","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\n# Preparing the data\nhousing = fetch_california_housing()\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full, random_state=42)\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\nnorm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\nmodel = tf.keras.Sequential([\n    norm_layer,\n    tf.keras.layers.Dense(50, activation=\"relu\"),\n    tf.keras.layers.Dense(50, activation=\"relu\"),\n    tf.keras.layers.Dense(50, activation=\"relu\"),\n    tf.keras.layers.Dense(1)\n])\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\nnorm_layer.adapt(X_train)\n\n# Training the model\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n\n# Evaluating the model\nmse_test, rmse_test = model.evaluate(X_test, y_test)\nX_new = X_test[:3]\ny_pred = model.predict(X_new)\ny_pred","block_group":"e1f4573611f246e9bfc76aa12c686f8b","execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.8345 - root_mean_squared_error: 0.9135 - val_loss: 0.4716 - val_root_mean_squared_error: 0.6868\nEpoch 2/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3817 - root_mean_squared_error: 0.6178 - val_loss: 1.2662 - val_root_mean_squared_error: 1.1252\nEpoch 3/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3547 - root_mean_squared_error: 0.5955 - val_loss: 0.5600 - val_root_mean_squared_error: 0.7483\nEpoch 4/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3379 - root_mean_squared_error: 0.5813 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7661\nEpoch 5/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3300 - root_mean_squared_error: 0.5744 - val_loss: 3.0386 - val_root_mean_squared_error: 1.7432\nEpoch 6/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3406 - root_mean_squared_error: 0.5836 - val_loss: 0.3477 - val_root_mean_squared_error: 0.5897\nEpoch 7/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3120 - root_mean_squared_error: 0.5586 - val_loss: 0.6509 - val_root_mean_squared_error: 0.8068\nEpoch 8/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3047 - root_mean_squared_error: 0.5520 - val_loss: 1.4405 - val_root_mean_squared_error: 1.2002\nEpoch 9/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.3052 - root_mean_squared_error: 0.5525 - val_loss: 1.6132 - val_root_mean_squared_error: 1.2701\nEpoch 10/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3091 - root_mean_squared_error: 0.5560 - val_loss: 2.8949 - val_root_mean_squared_error: 1.7014\nEpoch 11/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2992 - root_mean_squared_error: 0.5470 - val_loss: 0.2930 - val_root_mean_squared_error: 0.5413\nEpoch 12/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2938 - root_mean_squared_error: 0.5421 - val_loss: 0.4163 - val_root_mean_squared_error: 0.6452\nEpoch 13/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.2826 - root_mean_squared_error: 0.5316 - val_loss: 0.2793 - val_root_mean_squared_error: 0.5285\nEpoch 14/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2817 - root_mean_squared_error: 0.5308 - val_loss: 0.2899 - val_root_mean_squared_error: 0.5384\nEpoch 15/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2787 - root_mean_squared_error: 0.5279 - val_loss: 0.3087 - val_root_mean_squared_error: 0.5556\nEpoch 16/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.2776 - root_mean_squared_error: 0.5269 - val_loss: 0.2775 - val_root_mean_squared_error: 0.5268\nEpoch 17/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.2743 - root_mean_squared_error: 0.5237 - val_loss: 0.4015 - val_root_mean_squared_error: 0.6336\nEpoch 18/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2702 - root_mean_squared_error: 0.5198 - val_loss: 0.2823 - val_root_mean_squared_error: 0.5313\nEpoch 19/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2685 - root_mean_squared_error: 0.5182 - val_loss: 0.3353 - val_root_mean_squared_error: 0.5791\nEpoch 20/20\n363/363 [==============================] - 1s 2ms/step - loss: 0.2684 - root_mean_squared_error: 0.5181 - val_loss: 0.3097 - val_root_mean_squared_error: 0.5565\n162/162 [==============================] - 0s 923us/step - loss: 0.2845 - root_mean_squared_error: 0.5334\n1/1 [==============================] - 0s 55ms/step\n","output_type":"stream"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([[0.43979013],\n       [1.0232092 ],\n       [4.885579  ]], dtype=float32)"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/094556d4-810f-4026-a9ca-030428d4c162","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f8f7311d5ca8418297c9622c3c99bc0b","deepnote_cell_type":"text-cell-h3"},"source":"### Keras Functinal APIs for building Complex Models","block_group":"3e10864925d94b5cb14a8be13581a491"},{"cell_type":"code","metadata":{"source_hash":"5410e43a","execution_start":1741077906452,"execution_millis":92,"execution_context_id":"547cb16f-5512-451b-9c57-14af6f718a65","cell_id":"072c97da8b764a5eb1b271eeecec43ae","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\n# Preparing the data\nhousing = fetch_california_housing()\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full, random_state=42)\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\nnorm_layer = tf.keras.layers.Normalization()\n\n# Building the model\nhidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\nhidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\nconcat_layer = tf.keras.layers.Concatenate()\noutput_layer = tf.keras.layers.Dense(1)\n\ninput_ = tf.keras.layers.Input(shape=X_train.shape[1:])\nnormalized = norm_layer(input_)\nhidden1 = hidden_layer1(normalized)\nhidden2 = hidden_layer2(hidden1)\nconcat = concat_layer([input_, hidden2])\noutput = output_layer(concat)\n\nmodel = tf.keras.Model(inputs=[input_], outputs=[output])\n\nmodel.summary()\n\n","block_group":"9f942b36240e4fa0acfddde87c4221da","execution_count":35,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 8)]                  0         []                            \n                                                                                                  \n normalization_6 (Normaliza  (None, 8)                    17        ['input_2[0][0]']             \n tion)                                                                                            \n                                                                                                  \n dense_22 (Dense)            (None, 30)                   270       ['normalization_6[0][0]']     \n                                                                                                  \n dense_23 (Dense)            (None, 30)                   930       ['dense_22[0][0]']            \n                                                                                                  \n concatenate_3 (Concatenate  (None, 38)                   0         ['input_2[0][0]',             \n )                                                                   'dense_23[0][0]']            \n                                                                                                  \n dense_24 (Dense)            (None, 1)                    39        ['concatenate_3[0][0]']       \n                                                                                                  \n==================================================================================================\nTotal params: 1256 (4.91 KB)\nTrainable params: 1239 (4.84 KB)\nNon-trainable params: 17 (72.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/35884c76-b53b-4959-892a-169f5f3ea55f","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":23,"fromCodePoint":0}],"cell_id":"cf91a64ac04143ac9ff32e0735f335d2","deepnote_cell_type":"text-cell-p"},"source":"With multiple outputs: ","block_group":"e4b1ff3d95724669814e5c0123ea26e6"},{"cell_type":"code","metadata":{"source_hash":"8d97c100","execution_start":1741147108646,"execution_millis":24150,"execution_context_id":"2b1f8738-5fff-4f7e-aa9b-dde103a74d24","cell_id":"df244a2fde754474a1de25b86904f37c","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\n# Preparing the data\nhousing = fetch_california_housing()\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full, random_state=42)\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\n\n# Building the model\nnorm_layer = tf.keras.layers.Normalization()\n\ninput_wide = tf.keras.layers.Input(\n    shape=[5],\n    name=\"input_wide\"\n)\ninput_deep = tf.keras.layers.Input(\n    shape=[6],\n    name=\"input_deep\"\n)\n\nnorm_layer_wide = tf.keras.layers.Normalization()\nnorm_layer_deep = tf.keras.layers.Normalization()\n\nnorm_wide = norm_layer_wide(input_wide)\nnorm_deep = norm_layer_deep(input_deep)\n\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.concatenate([norm_wide, hidden2])\noutput = tf.keras.layers.Dense(1, name=\"output\")(concat)\naux_output = tf.keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n\n# model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])\n\n# For multiple outputs\nmodel = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output, aux_output])\nmodel.summary()\n\n# Training the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\n# model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n# For multiple outputs\nmodel.compile(\n    loss=[\"mse\", \"mse\"],\n    loss_weights=[0.9, 0.1],\n    optimizer=optimizer, metrics=[\"RootMeanSquaredError\"]\n)\n\n\nX_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\nX_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\nX_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\nX_new_wide, X_new_deep = X_test[:3, :5], X_test[:3, 2:]\n\nnorm_layer_wide.adapt(X_train_wide)\nnorm_layer_deep.adapt(X_train_deep)\n\n# history = model.fit(\n#     {\n#         \"input_wide\": X_train_wide,\n#         \"input_deep\": X_train_deep\n#     },\n#     y_train,\n#     epochs=20,\n#     validation_data=(\n#         {\n#             \"input_wide\": X_valid_wide,\n#             \"input_deep\": X_valid_deep\n#         },\n#         y_valid\n#     )\n# )\n\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints\", save_weights_only=True)\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n\nhistory = model.fit(\n    {\n        \"input_wide\": X_train_wide,\n        \"input_deep\": X_train_deep\n    },\n    {\n        \"output\": y_train,\n        \"aux_output\": y_train\n    },\n    epochs=20,\n    validation_data=(\n        {\n            \"input_wide\": X_valid_wide,\n            \"input_deep\": X_valid_deep\n        },\n        {\n            \"output\": y_valid,\n            \"aux_output\": y_valid\n        }\n    ),\n    callbacks=[\n        checkpoint_cb,\n        early_stopping_cb\n    ]\n)\n\n# mse_test = model.evaluate(\n#     {\n#         \"input_wide\": X_test_wide,\n#         \"input_deep\": X_test_deep\n#     },\n#     y_test\n# )\n\neval_result = model.evaluate(\n    {\n        \"input_wide\": X_test_wide,\n        \"input_deep\": X_test_deep\n    },\n    {\n        \"output\": y_test,\n        \"aux_output\": y_test\n    }\n)\n\n# y_pred = model.predict(\n#     {\n#         \"input_wide\": X_new_wide,\n#         \"input_deep\": X_new_deep\n#     }\n# )\n\ny_pred_main, y_pred_aux = model.predict(\n    {\n        \"input_wide\": X_new_wide,\n        \"input_deep\": X_new_deep\n    }\n)\n\nprint(y_pred_main)\nprint(y_pred_aux)\n","block_group":"706c80ae92fc4a7f995fd0fc7012212c","execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_deep (InputLayer)     [(None, 6)]                  0         []                            \n                                                                                                  \n normalization_20 (Normaliz  (None, 6)                    13        ['input_deep[0][0]']          \n ation)                                                                                           \n                                                                                                  \n input_wide (InputLayer)     [(None, 5)]                  0         []                            \n                                                                                                  \n dense_17 (Dense)            (None, 30)                   210       ['normalization_20[0][0]']    \n                                                                                                  \n normalization_19 (Normaliz  (None, 5)                    11        ['input_wide[0][0]']          \n ation)                                                                                           \n                                                                                                  \n dense_18 (Dense)            (None, 30)                   930       ['dense_17[0][0]']            \n                                                                                                  \n concatenate_6 (Concatenate  (None, 35)                   0         ['normalization_19[0][0]',    \n )                                                                   'dense_18[0][0]']            \n                                                                                                  \n output (Dense)              (None, 1)                    36        ['concatenate_6[0][0]']       \n                                                                                                  \n aux_output (Dense)          (None, 1)                    31        ['dense_18[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1231 (4.82 KB)\nTrainable params: 1207 (4.71 KB)\nNon-trainable params: 24 (104.00 Byte)\n__________________________________________________________________________________________________\nEpoch 1/20\n363/363 [==============================] - 2s 4ms/step - loss: 1.2322 - output_loss: 1.1722 - aux_output_loss: 1.7717 - output_root_mean_squared_error: 1.0827 - aux_output_root_mean_squared_error: 1.3310 - val_loss: 3.8718 - val_output_loss: 4.0565 - val_aux_output_loss: 2.2098 - val_output_root_mean_squared_error: 2.0141 - val_aux_output_root_mean_squared_error: 1.4866\nEpoch 2/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.5140 - output_loss: 0.4885 - aux_output_loss: 0.7427 - output_root_mean_squared_error: 0.6990 - aux_output_root_mean_squared_error: 0.8618 - val_loss: 2.7311 - val_output_loss: 2.8897 - val_aux_output_loss: 1.3037 - val_output_root_mean_squared_error: 1.6999 - val_aux_output_root_mean_squared_error: 1.1418\nEpoch 3/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.4487 - output_loss: 0.4339 - aux_output_loss: 0.5822 - output_root_mean_squared_error: 0.6587 - aux_output_root_mean_squared_error: 0.7630 - val_loss: 1.8558 - val_output_loss: 1.9702 - val_aux_output_loss: 0.8261 - val_output_root_mean_squared_error: 1.4037 - val_aux_output_root_mean_squared_error: 0.9089\nEpoch 4/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.4135 - output_loss: 0.4002 - aux_output_loss: 0.5334 - output_root_mean_squared_error: 0.6326 - aux_output_root_mean_squared_error: 0.7304 - val_loss: 1.1673 - val_output_loss: 1.2255 - val_aux_output_loss: 0.6429 - val_output_root_mean_squared_error: 1.1070 - val_aux_output_root_mean_squared_error: 0.8018\nEpoch 5/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3911 - output_loss: 0.3797 - aux_output_loss: 0.4942 - output_root_mean_squared_error: 0.6162 - aux_output_root_mean_squared_error: 0.7030 - val_loss: 0.8535 - val_output_loss: 0.8840 - val_aux_output_loss: 0.5798 - val_output_root_mean_squared_error: 0.9402 - val_aux_output_root_mean_squared_error: 0.7615\nEpoch 6/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3748 - output_loss: 0.3644 - aux_output_loss: 0.4686 - output_root_mean_squared_error: 0.6036 - aux_output_root_mean_squared_error: 0.6845 - val_loss: 0.6341 - val_output_loss: 0.6435 - val_aux_output_loss: 0.5494 - val_output_root_mean_squared_error: 0.8022 - val_aux_output_root_mean_squared_error: 0.7412\nEpoch 7/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3643 - output_loss: 0.3551 - aux_output_loss: 0.4474 - output_root_mean_squared_error: 0.5959 - aux_output_root_mean_squared_error: 0.6689 - val_loss: 0.5333 - val_output_loss: 0.5358 - val_aux_output_loss: 0.5101 - val_output_root_mean_squared_error: 0.7320 - val_aux_output_root_mean_squared_error: 0.7142\nEpoch 8/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3573 - output_loss: 0.3486 - aux_output_loss: 0.4354 - output_root_mean_squared_error: 0.5904 - aux_output_root_mean_squared_error: 0.6599 - val_loss: 0.4102 - val_output_loss: 0.4070 - val_aux_output_loss: 0.4390 - val_output_root_mean_squared_error: 0.6380 - val_aux_output_root_mean_squared_error: 0.6625\nEpoch 9/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3506 - output_loss: 0.3425 - aux_output_loss: 0.4237 - output_root_mean_squared_error: 0.5852 - aux_output_root_mean_squared_error: 0.6510 - val_loss: 0.4224 - val_output_loss: 0.4154 - val_aux_output_loss: 0.4850 - val_output_root_mean_squared_error: 0.6445 - val_aux_output_root_mean_squared_error: 0.6964\nEpoch 10/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3480 - output_loss: 0.3402 - aux_output_loss: 0.4185 - output_root_mean_squared_error: 0.5832 - aux_output_root_mean_squared_error: 0.6469 - val_loss: 0.4694 - val_output_loss: 0.4572 - val_aux_output_loss: 0.5784 - val_output_root_mean_squared_error: 0.6762 - val_aux_output_root_mean_squared_error: 0.7605\nEpoch 11/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3425 - output_loss: 0.3347 - aux_output_loss: 0.4120 - output_root_mean_squared_error: 0.5786 - aux_output_root_mean_squared_error: 0.6418 - val_loss: 0.3725 - val_output_loss: 0.3679 - val_aux_output_loss: 0.4144 - val_output_root_mean_squared_error: 0.6065 - val_aux_output_root_mean_squared_error: 0.6437\nEpoch 12/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3430 - output_loss: 0.3356 - aux_output_loss: 0.4090 - output_root_mean_squared_error: 0.5793 - aux_output_root_mean_squared_error: 0.6395 - val_loss: 0.4431 - val_output_loss: 0.4319 - val_aux_output_loss: 0.5438 - val_output_root_mean_squared_error: 0.6572 - val_aux_output_root_mean_squared_error: 0.7374\nEpoch 13/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3379 - output_loss: 0.3306 - aux_output_loss: 0.4031 - output_root_mean_squared_error: 0.5750 - aux_output_root_mean_squared_error: 0.6349 - val_loss: 0.3896 - val_output_loss: 0.3774 - val_aux_output_loss: 0.4998 - val_output_root_mean_squared_error: 0.6143 - val_aux_output_root_mean_squared_error: 0.7070\nEpoch 14/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3378 - output_loss: 0.3309 - aux_output_loss: 0.4000 - output_root_mean_squared_error: 0.5753 - aux_output_root_mean_squared_error: 0.6324 - val_loss: 0.3145 - val_output_loss: 0.3062 - val_aux_output_loss: 0.3900 - val_output_root_mean_squared_error: 0.5533 - val_aux_output_root_mean_squared_error: 0.6245\nEpoch 15/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3345 - output_loss: 0.3279 - aux_output_loss: 0.3935 - output_root_mean_squared_error: 0.5726 - aux_output_root_mean_squared_error: 0.6273 - val_loss: 0.4042 - val_output_loss: 0.3929 - val_aux_output_loss: 0.5054 - val_output_root_mean_squared_error: 0.6268 - val_aux_output_root_mean_squared_error: 0.7109\nEpoch 16/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3313 - output_loss: 0.3247 - aux_output_loss: 0.3910 - output_root_mean_squared_error: 0.5698 - aux_output_root_mean_squared_error: 0.6253 - val_loss: 0.3252 - val_output_loss: 0.3191 - val_aux_output_loss: 0.3796 - val_output_root_mean_squared_error: 0.5649 - val_aux_output_root_mean_squared_error: 0.6162\nEpoch 17/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3303 - output_loss: 0.3238 - aux_output_loss: 0.3886 - output_root_mean_squared_error: 0.5690 - aux_output_root_mean_squared_error: 0.6234 - val_loss: 0.3936 - val_output_loss: 0.3779 - val_aux_output_loss: 0.5341 - val_output_root_mean_squared_error: 0.6148 - val_aux_output_root_mean_squared_error: 0.7308\nEpoch 18/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3276 - output_loss: 0.3212 - aux_output_loss: 0.3854 - output_root_mean_squared_error: 0.5667 - aux_output_root_mean_squared_error: 0.6208 - val_loss: 0.3711 - val_output_loss: 0.3666 - val_aux_output_loss: 0.4114 - val_output_root_mean_squared_error: 0.6055 - val_aux_output_root_mean_squared_error: 0.6414\nEpoch 19/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3247 - output_loss: 0.3184 - aux_output_loss: 0.3809 - output_root_mean_squared_error: 0.5643 - aux_output_root_mean_squared_error: 0.6171 - val_loss: 0.3168 - val_output_loss: 0.3010 - val_aux_output_loss: 0.4591 - val_output_root_mean_squared_error: 0.5486 - val_aux_output_root_mean_squared_error: 0.6775\nEpoch 20/20\n363/363 [==============================] - 1s 3ms/step - loss: 0.3256 - output_loss: 0.3196 - aux_output_loss: 0.3796 - output_root_mean_squared_error: 0.5653 - aux_output_root_mean_squared_error: 0.6161 - val_loss: 0.5383 - val_output_loss: 0.5321 - val_aux_output_loss: 0.5942 - val_output_root_mean_squared_error: 0.7295 - val_aux_output_root_mean_squared_error: 0.7708\n162/162 [==============================] - 0s 2ms/step - loss: 0.3257 - output_loss: 0.3197 - aux_output_loss: 0.3805 - output_root_mean_squared_error: 0.5654 - aux_output_root_mean_squared_error: 0.6168\nWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f47f1df1630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 [==============================] - 0s 74ms/step\n[[0.43825158]\n [1.0390869 ]\n [3.54338   ]]\n[[0.5564438]\n [0.8994854]\n [3.553924 ]]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/caf2fb8e-962d-4872-85a8-302f9746bfb2","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"97c3053a5e0543af8bd57595d406a5df","deepnote_cell_type":"text-cell-h3"},"source":"### Fine-Tuning with Keras Tuner by build_model()","block_group":"724325a2583e4b7189089664431c9b6f"},{"cell_type":"code","metadata":{"source_hash":"8ffe0877","execution_start":1741231209398,"execution_millis":242318,"execution_context_id":"b314b417-1cc8-4e53-aeb7-2a5753fa593b","cell_id":"18a7d5445f16419aba6c45b8451f20c1","deepnote_cell_type":"code"},"source":"%pip install -q -U keras-tuner\n\nimport keras_tuner as kt\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\ndef build_model(hp):\n    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n    if optimizer == \"sgd\":\n        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n    else:\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Flatten())\n    for _ in range(n_hidden):\n        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model\n\n# Preparing the data\nfashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\nX_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\nX_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\nX_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\n\n# Training models\nrandom_search_tuner = kt.RandomSearch(\n    build_model, objective=\"val_accuracy\", max_trials=3, overwrite=True,\n    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42\n)\n\nrandom_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n\n# Retrieving the best model\ntop3_models = random_search_tuner.get_best_models(num_models=3)\nbest_model = top3_models[0]\n\n# Retrieving the best params\ntop3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\nbest_params = top3_params[0]\nbest_params.values\n\n# Retrieving the best trial\nbest_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\nbest_trial.summary()\n","block_group":"61fb20182066450bac7ae4831cfd4c6e","execution_count":20,"outputs":[{"output_type":"clear_output"},{"name":"stdout","text":"Trial 3 Complete [00h 01m 26s]\nval_accuracy: 0.004392764996737242\n\nBest val_accuracy So Far: 0.004392764996737242\nTotal elapsed time: 00h 03m 45s\nTrial 0 summary\nHyperparameters:\nn_hidden: 5\nn_neurons: 25\nlearning_rate: 0.0006562536901904111\noptimizer: sgd\nScore: 0.004392764996737242\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/cdfba053-85f2-47d8-a9ee-7f8fe4aff088","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"85ad795dd25a4474aa403b25a6c19208","deepnote_cell_type":"text-cell-h3"},"source":"### Fine-Tuning with Keras Tuner by HyperModel","block_group":"67bb1dbfb6d04bbda0e9f7af4f1d8626"},{"cell_type":"code","metadata":{"source_hash":"5aa832af","execution_start":1741240289971,"execution_millis":2323828,"execution_context_id":"df509657-e133-4bbf-8ea5-8613c65b74e8","cell_id":"18a5c9c146384afebec46d594f2785b1","deepnote_cell_type":"code"},"source":"%pip install -q -U keras-tuner\n\nimport keras_tuner as kt\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\n# Function for model building\ndef build_model(hp):\n    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n    if optimizer == \"sgd\":\n        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n    else:\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Flatten())\n    for _ in range(n_hidden):\n        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model\n\n# Class for tweaking model fitting parameters\nclass MyClassificationHyperModel(kt.HyperModel):\n    # Building a model\n    def build(self, hp):\n        return build_model(hp)\n    # Fitting a model and return the history object\n    def fit(self, hp, model, X, y, **kwargs):\n        if hp.Boolean(\"normalize\"):\n            norm_layer = tf.keras.layers.Normalization()\n            X = norm_layer(X)\n        return model.fit(X, y, **kwargs)\n\n# Preparing the data\nfashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\nX_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\nX_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n\n# Preprocessing of data\nX_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\n\n# Training models\nhyperband_tuner = kt.Hyperband(\n    MyClassificationHyperModel(),\n    objective=\"val_accuracy\",\n    max_epochs=10,\n    seed=42,\n    factor=3,\n    hyperband_iterations=2,\n    overwrite=True,\n    directory=\"my_fashion_mnist\",\n    project_name=\"hyperband\"\n)\n\nbayesian_opt_tuner = kt.BayesianOptimization(\n    MyClassificationHyperModel(),\n    objective=\"val_accuracy\",\n    seed=42,\n    max_trials=10,\n    alpha=1e-4,\n    beta=2.6,\n    overwrite=True,\n    directory=\"my_fashion_mnist\",\n    project_name=\"bayesian_opt\"\n)\n\nhyperband_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n\n# Retrieving the best model\ntop3_models = hyperband_tuner.get_best_models(num_models=3)\nbest_model = top3_models[0]\n\n# Retrieving the best params\ntop3_params = hyperband_tuner.get_best_hyperparameters(num_trials=3)\nbest_params = top3_params[0]\nbest_params.values\n\n# Retrieving the best trial\nbest_trial = hyperband_tuner.oracle.get_best_trials(num_trials=1)[0]\nbest_trial.summary()","block_group":"b5b667351159459bbc77ae3360d6f9fe","execution_count":3,"outputs":[{"output_type":"clear_output"},{"name":"stdout","text":"Trial 60 Complete [00h 01m 06s]\nval_accuracy: 0.8425999879837036\n\nBest val_accuracy So Far: 0.8880000114440918\nTotal elapsed time: 00h 38m 34s\nTrial 0055 summary\nHyperparameters:\nn_hidden: 7\nn_neurons: 247\nlearning_rate: 0.0003987720809096887\noptimizer: adam\nnormalize: True\ntuner/epochs: 10\ntuner/initial_epoch: 4\ntuner/bracket: 1\ntuner/round: 1\ntuner/trial_id: 0049\nScore: 0.8880000114440918\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b64e2a16-07b5-4bc2-8908-29c135af8705","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"74022a90cc474998a1de386d39edabc9","deepnote_cell_type":"text-cell-h3"},"source":"### Training MNIST Dataset","block_group":"87dc953c5a5b45cda8e8329e358472b2"},{"cell_type":"code","metadata":{"source_hash":"2df12cc5","execution_start":1741248351505,"execution_millis":1085904,"execution_context_id":"a2e86020-20d7-47e4-8a0d-2eba324d7f45","cell_id":"504c31bbf99a4e4c9d07816368f9f445","deepnote_cell_type":"code"},"source":"%pip install -q -U keras-tuner\n\nimport keras_tuner as kt\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\n# Function for model building\ndef build_model(hp):\n    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n    if optimizer == \"sgd\":\n        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n    else:\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Flatten())\n    for _ in range(n_hidden):\n        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model\n\n# Class for tweaking model fitting parameters\nclass MyClassificationHyperModel(kt.HyperModel):\n    # Building a model\n    def build(self, hp):\n        return build_model(hp)\n    # Fitting a model and return the history object\n    def fit(self, hp, model, X, y, **kwargs):\n        if hp.Boolean(\"normalize\"):\n            norm_layer = tf.keras.layers.Normalization()\n            X = norm_layer(X)\n        return model.fit(X, y, **kwargs)\n\n# Preparing the data\nfashion_mnist = tf.keras.datasets.mnist.load_data()\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\nX_train, y_train = X_train_full[:-10000], y_train_full[:-10000]\nX_valid, y_valid = X_train_full[-10000:], y_train_full[-10000:]\n\n# Preprocessing of data\nX_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n# Preprocessing the data\ntf.keras.utils.set_random_seed(42)\n\n# Training models\nbayesian_opt_tuner = kt.BayesianOptimization(\n    MyClassificationHyperModel(),\n    objective=\"val_accuracy\",\n    seed=42,\n    max_trials=10,\n    alpha=1e-4,\n    beta=2.6,\n    overwrite=True,\n    directory=\"my_fashion_mnist\",\n    project_name=\"bayesian_opt\"\n)\n\nbayesian_opt_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n\n# Retrieving the best model\ntop3_models = bayesian_opt_tuner.get_best_models(num_models=3)\nbest_model = top3_models[0]\n\n# Retrieving the best params\ntop3_params = bayesian_opt_tuner.get_best_hyperparameters(num_trials=3)\nbest_params = top3_params[0]\nbest_params.values\n\n# Retrieving the best trial\nbest_trial = bayesian_opt_tuner.oracle.get_best_trials(num_trials=1)[0]\nbest_trial.summary()","block_group":"ef942285a8fb47f48f0d5b48c0169db7","execution_count":1,"outputs":[{"output_type":"clear_output"},{"name":"stdout","text":"Trial 10 Complete [00h 02m 24s]\nval_accuracy: 0.7185999751091003\n\nBest val_accuracy So Far: 0.9779000282287598\nTotal elapsed time: 00h 17m 52s\nTrial 02 summary\nHyperparameters:\nn_hidden: 2\nn_neurons: 251\nlearning_rate: 0.001715074355925934\noptimizer: adam\nnormalize: False\nScore: 0.9779000282287598\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/70941eaa-2302-4371-a61d-a98f6c45d3cf","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=968d3c27-50e7-4d42-bdd9-442f6904c1c2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"ee7800206f494be99d18033bb28dbff9"}}