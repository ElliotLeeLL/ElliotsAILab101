{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"dea00bdb209148a9912ca87a38f30612","deepnote_cell_type":"text-cell-h1"},"source":"# Loading and Preprocessing\r Data with TensorFlow","block_group":"9b51d11f40e146c795ed0a0cea9b2ca6"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b7e9d1d791944f6fb1b7a899f92ac609","deepnote_cell_type":"text-cell-h3"},"source":"### The tf.data API","block_group":"25767d222d2e49fc9091d64d4748568c"},{"cell_type":"code","metadata":{"source_hash":"bc950d8c","execution_start":1742480669258,"execution_millis":2504,"execution_context_id":"7120b53d-4818-40f0-a570-08db85bc90d3","cell_id":"e32cef3fe37c48bfae8a35ad9b6c6f53","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\n# X = tf.range(10)\n# dataset = tf.data.Dataset.from_tensor_slices(X)\n# for item in dataset:\n#     print(item)\n\n# X_nested = {'a':([1,2,3],[4,5,6]), 'b':[7,8,9]}\n# dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n# for item in dataset:\n#     print(item)\n\n# dataset = tf.data.Dataset.range(10)\n# dataset = dataset.repeat(3).batch(7)\n# for item in dataset:\n#     print(item)\n\n# dataset = dataset.map(lambda x: x * 2)\n# dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)\n# for item in dataset.take(2):\n#     print(item)\n\n# dataset = tf.data.Dataset.range(10).repeat(2)\n# dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n# for item in dataset:\n#     print(item)\n\ndataset = tf.data.Dataset.range(10)\ndataset = dataset.shuffle(buffer_size=4, seed=42, reshuffle_each_iteration=False).repeat(2).batch(7)\nfor item in dataset:\n    print(item)\n","block_group":"e32cef3fe37c48bfae8a35ad9b6c6f53","execution_count":1,"outputs":[{"name":"stderr","text":"2025-03-20 14:24:29.504849: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-20 14:24:29.535800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-20 14:24:29.535933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-20 14:24:29.537101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-20 14:24:29.542987: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-20 14:24:29.544020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-03-20 14:24:30.623256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\ntf.Tensor([0 1 3 4 5 2 6], shape=(7,), dtype=int64)\ntf.Tensor([9 7 8 0 1 3 4], shape=(7,), dtype=int64)\ntf.Tensor([5 2 6 9 7 8], shape=(6,), dtype=int64)\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/b351ee23-ebbf-49a4-80ab-bc196f2d49e3","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c5bad63e083446d7ad9aad786085a39c","deepnote_cell_type":"text-cell-h3"},"source":"### Reading data from multiple filepaths","block_group":"edb70784ac7c4a1ba1f669844e8d41e9"},{"cell_type":"code","metadata":{"source_hash":"32daca5b","execution_start":1742480671818,"execution_millis":0,"execution_context_id":"7120b53d-4818-40f0-a570-08db85bc90d3","cell_id":"3bbef8c7de9844089db235f384b3fc13","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\nn_inputs = 8\nx_mean = -1\nx_std = -1\n\ndef parse_csv_line(line):\n    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n    fielfs = tf.io.decode_csv(line, record_defaults=defs)\n    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n\ndef preprocess(line):\n    x, y = parse_csv_line(line)\n    return (x - x_mean) / x_std, y\n\ndef csv_reader_dataset(\n    filepaths,\n    n_readers=5, \n    n_read_threads=None, \n    shuffle_buffer_size=10_000, \n    n_parse_threads=5,\n    seed=42,\n    batch_size=32):\n    dataset = tf.data.Dataset.list_files(filepaths)\n    dataset = dataset.interleave(\n        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n        cycle_length=n_readers,\n        num_parallel_calls=n_read_threads\n    )\n    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n    return dataset.batch(batch_size).prefetch(1)","block_group":"210b8d22a79d405fa971c71e78ba4f56","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"834b583968624ad290ad6bf172643c38","deepnote_cell_type":"text-cell-h3"},"source":"### The TFRecord Format","block_group":"aa9be781146a4ed6a9126faa0845a4c0"},{"cell_type":"code","metadata":{"source_hash":"279ec978","execution_start":1742480671867,"execution_millis":375,"execution_context_id":"7120b53d-4818-40f0-a570-08db85bc90d3","cell_id":"395e888a2fc54ca0817d8a5aa1c1ca07","deepnote_cell_type":"code"},"source":"import tensorflow as tf\n\nwith tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n    f.write(b\"This is the first record\")\n    f.write(b\"And this is the second\")\nfilePaths = [\"my_data.tfrecord\"]\ndataset = tf.data.TFRecordDataset.list_files(filePaths)\ndataset = dataset.interleave(\n    lambda filepath: tf.data.TFRecordDataset(filepath),\n    cycle_length=5,\n    num_parallel_calls=None\n)\n\nfor item in dataset:\n    print(item)","block_group":"dc04007338ad489493f17b4c9940fcb6","execution_count":3,"outputs":[{"name":"stdout","text":"tf.Tensor(b'This is the first record', shape=(), dtype=string)\ntf.Tensor(b'And this is the second', shape=(), dtype=string)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c5d6d30e-16a2-423a-b692-462a0bd53e57","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a77d004af9af42de982f4792fb73ffb2","deepnote_cell_type":"text-cell-h3"},"source":"### TensorFlow Protobufs","block_group":"e7fb844d27cc4c789c2024ed152920e9"},{"cell_type":"code","metadata":{"source_hash":"17d609b5","execution_start":1742480699477,"execution_millis":345,"execution_context_id":"7120b53d-4818-40f0-a570-08db85bc90d3","cell_id":"04300bdb5a87400ab2226aaaf8b0dc43","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom tensorflow.train import BytesList, FloatList, Int64List\nfrom tensorflow.train import Feature, Features, Example\n\n# Prepare the Example protocol buffer\nperson_example = Example(\n    features=Features(\n        feature={\n            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n            \"id\": Feature(int64_list=Int64List(value=[123])),\n            \"emails\": Feature(bytes_list=BytesList(value=[\n                b\"a@b.com\",\n                b\"c@d.com\"\n            ]))\n        }\n    )\n)\n\n# Write the Example to the TFRecord file\nwith tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n    for _ in range(5):\n        f.write(person_example.SerializeToString())\n\n# Read the TFRecord file\nfeature_description = {\n    \"name\": tf.io.FixedLenFeature([], tf.string),\n    \"id\": tf.io.FixedLenFeature([], tf.int64),\n    \"emails\": tf.io.VarLenFeature(tf.string),\n}\n\ndef parse(serialized_example):\n    return tf.io.parse_single_example(serialized_example, feature_description)\n\n# dataset = tf.data.TFRecordDataset(\"my_contacts.tfrecord\").map(parse)\n\n# or you can batch process the dataset\ndataset = tf.data.TFRecordDataset(\"my_contacts.tfrecord\").batch(2).map(parse)\nfor item in dataset:\n    print(item)\n","block_group":"77e3a26577a34aa4a7a3db31910628a4","execution_count":10,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_137/2837857720.py\", line 32, in parse  *\n        return tf.io.parse_single_example(serialized_example, feature_description)\n\n    ValueError: Input serialized must be a scalar\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mparse_single_example(serialized_example, feature_description)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# dataset = tf.data.TFRecordDataset(\"my_contacts.tfrecord\").map(parse)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# or you can batch process the dataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFRecordDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_contacts.tfrecord\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_filexbqbwmtr.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__parse\u001b[0;34m(serialized_example)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_single_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_description\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/venv/lib/python3.10/site-packages/tensorflow/python/ops/parsing_ops.py:1149\u001b[0m, in \u001b[0;36m_assert_scalar\u001b[0;34m(value, name)\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must be a scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_137/2837857720.py\", line 32, in parse  *\n        return tf.io.parse_single_example(serialized_example, feature_description)\n\n    ValueError: Input serialized must be a scalar\n"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/33aaf172-5624-4ec3-bc49-896b93839147","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"23b2285cff2a4bd69277555235df67fe","deepnote_cell_type":"text-cell-h3"},"source":"### Keras Preprocessing Layers","block_group":"c0ef666280f745d69b7881c9aa28381a"},{"cell_type":"code","metadata":{"source_hash":"b45c30cd","execution_start":1742375501146,"execution_millis":127,"execution_context_id":"34e1e585-c1bd-4d06-b30b-e39bd01df53a","deepnote_to_be_reexecuted":true,"cell_id":"6fe5a23c8e044450ae750909ee05df42","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\n\n# age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])\n# discretize_layer = tf.keras.layers.Discretization(bin_boundaries=[18., 50.])\n# age_discretized = discretize_layer(age)\n# age_discretized\n\n# age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])\n# discretize_layer = tf.keras.layers.Discretization(num_bins=3)\n# discretize_layer.adapt(age)\n# age_discretized = discretize_layer(age)\n# age_discretized\n# onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\n# onehot_layer(age_discretized)\n# two_age_categories = np.array([[1,0], [2,2], [2,0]])\n# onehot_layer(two_age_categories)\n# onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3 + 3)\n# onehot_layer(two_age_categories + [0, 3])\n\n# cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n# str_lookup_layer = tf.keras.layers.StringLookup()\n# str_lookup_layer.adapt(cities)\n# str_lookup_layer(cities)\n# str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])\n\n# cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n# str_lookup_layer = tf.keras.layers.StringLookup(output_mode=\"one_hot\")\n# str_lookup_layer.adapt(cities)\n# str_lookup_layer(cities)\n# str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])\n\n# cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n# str_lookup_layer = tf.keras.layers.StringLookup(num_oov_indices=5)\n# str_lookup_layer.adapt(cities)\n# str_lookup_layer(cities)\n# str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Foo\"], [\"Bar\"], [\"Baz\"]])\n\n# hashing_layer = tf.keras.layers.Hashing(num_bins=10)\n# hashing_layer([[\"Paris\"], [\"Tokyo\"], [\"Auckland\"], [\"Montreal\"]])\n\n# tf.random.set_seed(42)\n# embedding_layer = tf.keras.layers.Embedding(input_dim=5, output_dim=2)\n# embedding_layer(tf.constant([2,4,2]))\n\n# tf.random.set_seed(42)\n# ocean_prox = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n# str_lookup_layer = tf.keras.layers.StringLookup()\n# str_lookup_layer.adapt(ocean_prox)\n# lookup_and_embed = tf.keras.Sequential([\n#     tf.keras.layers.Input(shape=(1,), dtype=tf.string),  # Specify string input\n#     str_lookup_layer,\n#     tf.keras.layers.Embedding(input_dim=str_lookup_layer.vocabulary_size(), output_dim=2),\n# ])\n# lookup_and_embed(tf.constant([[\"<1H OCEAN\"], [\"ISLAND\"], [\"<1H OCEAN\"]]))\n\n# train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"Be, be, be.\"] \n# text_vec_layer = tf.keras.layers.TextVectorization()\n# text_vec_layer.adapt(train_data)\n# text_vec_layer([\"Be good!\", \"Question: be or be?\"])\n\n# train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"Be, be, be.\"] \n# text_vec_layer = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")\n# text_vec_layer.adapt(train_data)\n# text_vec_layer([\"Be good!\", \"Question: be or be?\"])\n\n","block_group":"9a105458b88a478aa4c3d4b0a43815e1","execution_count":33,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[0.         0.         0.         0.         0.         0.91629076\n  0.91629076 0.         0.91629076 0.         0.91629076 0.91629076\n  0.         0.         0.         0.         0.        ]\n [0.         0.6931472  0.6931472  0.6931472  0.         0.\n  0.         0.91629076 0.         0.91629076 0.         0.\n  0.91629076 0.91629076 0.         0.         0.91629076]\n [0.         0.6931472  0.6931472  0.6931472  0.91629076 0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.91629076 0.91629076 0.        ]], shape=(3, 17), dtype=float32)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2793168e-5355-46f7-80ac-b1c5018f8ff8","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"43f14dc44b534c0e82425f426f4e7f97","deepnote_cell_type":"text-cell-h3"},"source":"### Using Pretrained Language Model Components for Text Embedding","block_group":"2d7bbb36f5e74963ad99bb4a0198dc6a"},{"cell_type":"code","metadata":{"source_hash":"36ea35bc","execution_start":1742376626335,"execution_millis":6102,"execution_context_id":"34e1e585-c1bd-4d06-b30b-e39bd01df53a","deepnote_to_be_reexecuted":true,"cell_id":"aecad5581e1c45618aa5e84b532417c5","deepnote_cell_type":"code"},"source":"!pip install --upgrade pip\n!pip install tensorflow_hub\nimport tensorflow_hub as hub\n\nhub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\nsentence_embeddings = hub_layer(tf.constant([\"To be\", \"Not to be\"]))\nsentence_embeddings.numpy().round(2)","block_group":"35ce3bd43fe64966a2256b3fc0effe14","execution_count":39,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-25.0.1\nRequirement already satisfied: tensorflow_hub in /root/venv/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: numpy>=1.12.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_hub) (2.1.3)\nRequirement already satisfied: protobuf>=3.19.6 in /root/venv/lib/python3.10/site-packages (from tensorflow_hub) (4.25.6)\nRequirement already satisfied: tf-keras>=2.14.1 in /root/venv/lib/python3.10/site-packages (from tensorflow_hub) (2.19.0)\nRequirement already satisfied: tensorflow<2.20,>=2.19 in /root/venv/lib/python3.10/site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.19.0)\nRequirement already satisfied: absl-py>=1.0.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\nRequirement already satisfied: packaging in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (24.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (65.5.0)\nRequirement already satisfied: six>=1.12.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.70.0)\nRequirement already satisfied: tensorboard~=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.0)\nRequirement already satisfied: keras>=3.5.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.9.0)\nRequirement already satisfied: h5py>=3.11.0 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.12.1)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.5.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\nRequirement already satisfied: rich in /root/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (13.9.4)\nRequirement already satisfied: namex in /root/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\nRequirement already satisfied: optree in /root/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.14.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /root/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /root/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /root/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /root/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /root/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n","output_type":"stream"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"array([[-0.25,  0.28,  0.01,  0.1 ,  0.14,  0.16,  0.25,  0.02,  0.07,\n         0.13, -0.19,  0.06, -0.04, -0.07,  0.  , -0.08, -0.14, -0.16,\n         0.02, -0.24,  0.16, -0.16, -0.03,  0.03, -0.14,  0.03, -0.09,\n        -0.04, -0.14, -0.19,  0.07,  0.15,  0.18, -0.23, -0.07, -0.08,\n         0.01, -0.01,  0.09,  0.14, -0.03,  0.03,  0.08,  0.1 , -0.01,\n        -0.03, -0.07, -0.1 ,  0.05,  0.31],\n       [-0.2 ,  0.2 , -0.08,  0.02,  0.19,  0.05,  0.22, -0.09,  0.02,\n         0.19, -0.02, -0.14, -0.2 , -0.04,  0.01, -0.07, -0.22, -0.1 ,\n         0.16, -0.44,  0.31, -0.1 ,  0.23,  0.15, -0.05,  0.15, -0.13,\n        -0.04, -0.08, -0.16, -0.1 ,  0.13,  0.13, -0.18, -0.04,  0.03,\n        -0.1 , -0.07,  0.07,  0.03, -0.08,  0.02,  0.05,  0.07, -0.14,\n        -0.1 , -0.18, -0.13, -0.04,  0.15]], dtype=float32)"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/7352f348-c11c-4868-ad75-49a1c0dd8a42","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e818f3865bf14560938c12a2d973984d","deepnote_cell_type":"text-cell-h3"},"source":"### The TensorFlow Datasets Project","block_group":"1cd37c4e7a4c4768b4d7182e34c5b613"},{"cell_type":"code","metadata":{"source_hash":"73fc08b1","execution_start":1742433844539,"execution_millis":23840,"execution_context_id":"06fe8e6e-79c1-48c4-acf5-cdc502f5ce84","deepnote_to_be_reexecuted":true,"cell_id":"3d5dbd07be9f4021b56717ae65012619","deepnote_cell_type":"code"},"source":"!pip install --upgrade pip\n!pip install tensorflow_datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\ntrain_set, valid_set, test_set = tfds.load(\n    name=\"mnist\",\n    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n    as_supervised=True,\n)\n\ntrain_set = train_set.shuffle(buffer_size=10_000, seed=42).batch(32).prefetch(2)\nvalid_set = valid_set.batch(32).cache()\ntest_set = test_set.batch(32).cache()\ntf.random.set_seed(42)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(10, activation=\"softmax\"),\n])\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\nhistory = model.fit(train_set, epochs=5, validation_data=valid_set)\n\ntest_loss, test_accuracy = model.evaluate(test_set)","block_group":"e308e3ee6489407dadc61c85fd3530f0","execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (25.0.1)\nRequirement already satisfied: tensorflow_datasets in /root/venv/lib/python3.10/site-packages (4.9.8)\nRequirement already satisfied: absl-py in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\nRequirement already satisfied: array_record>=0.5.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.7.1)\nRequirement already satisfied: dm-tree in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.9)\nRequirement already satisfied: etils>=1.6.0 in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (1.12.2)\nRequirement already satisfied: immutabledict in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.2.1)\nRequirement already satisfied: numpy in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.2)\nRequirement already satisfied: promise in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\nRequirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (3.20.3)\nRequirement already satisfied: psutil in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (6.0.0)\nRequirement already satisfied: pyarrow in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (17.0.0)\nRequirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\nRequirement already satisfied: simple_parsing in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.7)\nRequirement already satisfied: tensorflow-metadata in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.16.1)\nRequirement already satisfied: termcolor in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\nRequirement already satisfied: toml in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\nRequirement already satisfied: wrapt in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nRequirement already satisfied: einops in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (0.8.1)\nRequirement already satisfied: typing_extensions in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.12.2)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2024.6.1)\nRequirement already satisfied: importlib_resources in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (6.5.2)\nRequirement already satisfied: zipp in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\nRequirement already satisfied: attrs>=18.2.0 in /root/venv/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\nRequirement already satisfied: six in /root/venv/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\nRequirement already satisfied: docstring-parser<1.0,>=0.15 in /root/venv/lib/python3.10/site-packages (from simple_parsing->tensorflow_datasets) (0.16)\nEpoch 1/5\n1688/1688 [==============================] - 9s 5ms/step - loss: 10.1105 - accuracy: 0.8337 - val_loss: 7.1571 - val_accuracy: 0.8612\nEpoch 2/5\n1688/1688 [==============================] - 3s 1ms/step - loss: 5.7413 - accuracy: 0.8794 - val_loss: 5.7547 - val_accuracy: 0.8830\nEpoch 3/5\n1688/1688 [==============================] - 3s 1ms/step - loss: 5.2472 - accuracy: 0.8832 - val_loss: 6.5155 - val_accuracy: 0.8625\nEpoch 4/5\n1688/1688 [==============================] - 3s 2ms/step - loss: 5.0246 - accuracy: 0.8867 - val_loss: 6.5611 - val_accuracy: 0.8645\nEpoch 5/5\n1688/1688 [==============================] - 3s 1ms/step - loss: 4.8307 - accuracy: 0.8881 - val_loss: 5.8695 - val_accuracy: 0.8782\n313/313 [==============================] - 1s 4ms/step - loss: 5.5822 - accuracy: 0.8851\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/05917947-90c2-471f-bc9f-415a6645b0eb","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3cf57cc9021d47dbb9e829b47bce0622","deepnote_cell_type":"text-cell-h3"},"source":"### Process MNIST dataset","block_group":"aefc507718a546c980c71723dddd8df8"},{"cell_type":"code","metadata":{"source_hash":"c1982721","execution_start":1742459588703,"execution_millis":38016,"execution_context_id":"9f8e8f02-21bb-4b02-bc6b-156aa693e721","deepnote_to_be_reexecuted":true,"cell_id":"4a28d0f015f548eaa3b20217719b9ec0","deepnote_cell_type":"code"},"source":"!pip install --upgrade pip\n!pip install tensorflow_datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.train import BytesList, FloatList, Int64List\nfrom tensorflow.train import Feature, Features, Example\nfrom contextlib import ExitStack\nimport numpy as np\n\n(X_train_full, y_train_full), (X_test_full, y_test_full) = tf.keras.datasets.fashion_mnist.load_data()\nX_valid, X_train = X_train_full[:1000], X_train_full[-1000:]\ny_valid, y_train = y_train_full[:1000], y_train_full[-1000:]\nX_test = X_test_full[-1000:]\ny_test = y_test_full[-1000:]\n\ntf.random.set_seed(42)\ntrain_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_set = train_set.shuffle(len(X_train), seed=42)\nvalid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\ntest_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\ndef create_examples(dataset):\n    res = []\n    for image, label in dataset:\n        # Serialize the image tensor properly as bytes\n        image_example = Example(\n            features=Features(\n                feature={\n                    \"label\": Feature(int64_list=Int64List(value=[label.numpy()])),  # Ensure label is converted to int\n                    \"image\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(image).numpy()])),\n                }\n            )\n        )\n        res.append(image_example)\n    return res\n\ndef write_tfrecords(name, examples, n_shards):\n    paths = [\n        f\"{name}_{str(i).zfill(3)}.tfrecord\"\n        for i in range(n_shards)\n    ]\n    with ExitStack() as stack:\n        writers = [\n            stack.enter_context(tf.io.TFRecordWriter(path))\n            for path in paths\n        ]\n        for index, example in enumerate(examples):\n            shard = index % n_shards\n            writers[shard].write(example.SerializeToString())\n    return paths\n\ntrain_paths = write_tfrecords(\"image_data_train\", create_examples(train_set), 2)\nvalid_paths = write_tfrecords(\"image_data_valid\", create_examples(valid_set), 2)\ntest_paths = write_tfrecords(\"image_data_test\", create_examples(test_set), 2)\n\ndef preprocess(serialized_example):\n    feature_description = {\n        \"label\": tf.io.FixedLenFeature([], tf.int64),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n    }\n    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)\n    image = tf.io.parse_tensor(parsed_example['image'], out_type=tf.uint8)\n    image = tf.reshape(image, [28, 28])\n    return image, parsed_example['label']\n\ndef create_dataset(\n    paths,\n    n_read_threads=5,\n    shuffle_buffer_size=None,\n    n_parse_threads=5,\n    batch_size=2,\n    cache=True\n):\n\n    dataset = tf.data.TFRecordDataset(paths, num_parallel_reads=n_read_threads)\n    if cache:\n        dataset = dataset.cache()\n    if shuffle_buffer_size:\n        dataset = dataset.shuffle(shuffle_buffer_size)\n    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(1)\n    return dataset\n\ntrain_set = create_dataset(train_paths, shuffle_buffer_size=60000)\nvalid_set = create_dataset(valid_paths)\ntest_set = create_dataset(test_paths)\n\ntf.random.set_seed(42)\nstandardization = tf.keras.layers.Normalization(input_shape=[28, 28])\n\n# Use sample_image_batches with corrected indexing to extract the first element explicitly\nsample_image_batches = train_set.take(100).map(lambda image, label: image)  # Ensure proper extraction of images\nsample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n                                axis=0).astype(np.float32)\nstandardization.adapt(sample_images)\n\nmodel = tf.keras.Sequential([\n    standardization,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=\"nadam\", metrics=[\"accuracy\"])\nmodel.fit(train_set, epochs=15, validation_data=valid_set)","block_group":"1c697f3ee0cf4fc78aea3060e456410c","execution_count":44,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (25.0.1)\nRequirement already satisfied: tensorflow_datasets in /root/venv/lib/python3.10/site-packages (4.9.8)\nRequirement already satisfied: absl-py in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\nRequirement already satisfied: array_record>=0.5.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.7.1)\nRequirement already satisfied: dm-tree in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.9)\nRequirement already satisfied: etils>=1.6.0 in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (1.12.2)\nRequirement already satisfied: immutabledict in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.2.1)\nRequirement already satisfied: numpy in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.2)\nRequirement already satisfied: promise in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\nRequirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (3.20.3)\nRequirement already satisfied: psutil in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (6.0.0)\nRequirement already satisfied: pyarrow in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (17.0.0)\nRequirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\nRequirement already satisfied: simple_parsing in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.7)\nRequirement already satisfied: tensorflow-metadata in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.16.1)\nRequirement already satisfied: termcolor in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\nRequirement already satisfied: toml in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\nRequirement already satisfied: wrapt in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nRequirement already satisfied: einops in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (0.8.1)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2024.6.1)\nRequirement already satisfied: importlib_resources in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (6.5.2)\nRequirement already satisfied: typing_extensions in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.12.2)\nRequirement already satisfied: zipp in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\nRequirement already satisfied: attrs>=18.2.0 in /root/venv/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\nRequirement already satisfied: six in /root/venv/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\nRequirement already satisfied: docstring-parser<1.0,>=0.15 in /root/venv/lib/python3.10/site-packages (from simple_parsing->tensorflow_datasets) (0.16)\nEpoch 1/15\n500/500 [==============================] - 3s 5ms/step - loss: 1.0324 - accuracy: 0.6530 - val_loss: 0.8376 - val_accuracy: 0.7520\nEpoch 2/15\n500/500 [==============================] - 3s 5ms/step - loss: 0.5301 - accuracy: 0.8130 - val_loss: 0.6473 - val_accuracy: 0.7910\nEpoch 3/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.4204 - accuracy: 0.8420 - val_loss: 0.8783 - val_accuracy: 0.7710\nEpoch 4/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.3577 - accuracy: 0.8670 - val_loss: 0.7146 - val_accuracy: 0.8000\nEpoch 5/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.8980 - val_loss: 0.8152 - val_accuracy: 0.7630\nEpoch 6/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.2269 - accuracy: 0.9140 - val_loss: 0.6861 - val_accuracy: 0.8140\nEpoch 7/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.2030 - accuracy: 0.9230 - val_loss: 0.8933 - val_accuracy: 0.7900\nEpoch 8/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.2403 - accuracy: 0.9160 - val_loss: 1.0516 - val_accuracy: 0.7770\nEpoch 9/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9300 - val_loss: 0.8313 - val_accuracy: 0.8110\nEpoch 10/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1635 - accuracy: 0.9340 - val_loss: 0.8394 - val_accuracy: 0.7970\nEpoch 11/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1211 - accuracy: 0.9540 - val_loss: 0.8852 - val_accuracy: 0.8110\nEpoch 12/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1477 - accuracy: 0.9480 - val_loss: 0.9782 - val_accuracy: 0.8150\nEpoch 13/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1198 - accuracy: 0.9660 - val_loss: 0.9334 - val_accuracy: 0.7990\nEpoch 14/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9600 - val_loss: 0.9731 - val_accuracy: 0.8130\nEpoch 15/15\n500/500 [==============================] - 2s 4ms/step - loss: 0.1175 - accuracy: 0.9540 - val_loss: 1.1456 - val_accuracy: 0.8050\n","output_type":"stream"},{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"<keras.src.callbacks.History at 0x7f37bceac220>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/0cfe751a-82b4-4e5e-8a0a-bb8e37680a8f","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"601bf435f2e14e70aa067acd21e95afe","deepnote_cell_type":"text-cell-h3"},"source":"### Process IMDB dataset","block_group":"6f7a96f064bb47999dae6e341ad8e78a"},{"cell_type":"code","metadata":{"source_hash":"3afc09ee","execution_start":1742537490852,"execution_millis":104414,"execution_context_id":"ff1c1253-54c2-4182-a8b1-3695b5561d44","cell_id":"a3fa6e73b7f244c4aef6ec8108bfdca1","deepnote_cell_type":"code"},"source":"!pip install --upgrade pip\n!pip install tensorflow_datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom pathlib import Path\nimport numpy as np\n\n# # Step 1: Download the dataset\n# root = \"https://ai.stanford.edu/~amaas/data/sentiment/\"\n# filename = \"aclImdb_v1.tar.gz\"\n# filepath = tf.keras.utils.get_file(filename, root + filename, extract=True)\n\n# if \"_extracted\" in filepath:\n#     path = Path(filepath) / \"aclImdb\"\n# else:\n#     path = Path(filepath).with_name(\"aclImdb\")\n\n# # Step 2: Prepare the dataset\n# def review_paths(dirpath):\n#     return [\n#         str(path)\n#         for path in dirpath.glob(\"*.txt\")\n#     ]\n\n# train_pos = review_paths(path / \"train\" / \"pos\")\n# train_neg = review_paths(path / \"train\" / \"neg\")\n# test_valid_pos = review_paths(path / \"test\" / \"pos\")\n# test_valid_neg = review_paths(path / \"test\" / \"neg\")\n\n# np.random.shuffle(test_valid_pos)\n\n# test_pos = test_valid_pos[:5000]\n# test_neg = test_valid_neg[:5000]\n# valid_pos = test_valid_pos[5000:]\n# valid_neg = test_valid_neg[5000:]\n\n# # Step 3: Create the dataset\n# def imdb_dataset(filepaths_positive, filepaths_negative):\n#     reviews = []\n#     labels = []\n#     for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n#         for filepath in filepaths:\n#             with open(filepath) as review:\n#                 reviews.append(review.read())\n#                 labels.append(label)\n#     return tf.data.Dataset.from_tensor_slices((tf.constant(reviews), tf.constant(labels)))\n\n# # For large datasets that don't fit in memory\n# # def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n# #     dataset_neg = tf.data.TextLineDataset(filepaths_negative, num_parallel_reads=n_read_threads)\n# #     dataset_pos = tf.data.TextLineDataset(filepaths_positive, num_parallel_reads=n_read_threads)\n# #     dataset_neg = dataset_neg.map(lambda x: (x, 0))\n# #     dataset_pos = dataset_pos.map(lambda x: (x, 1))\n# #     return dataset_neg.concatenate(dataset_pos, dataset_neg)\n\n# tf.random.set_seed(42)\n# batch_size = 32\n# train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)\n# valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n# test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)\n\n# # Step 4: Create and Train the model\nmax_tokens = 1000\n# sample_review = train_set.map(lambda text, label: text)\ntext_vectorization = tf.keras.layers.TextVectorization(max_tokens=max_tokens, output_mode=\"tf_idf\")\n# text_vectorization.adapt(sample_review)\n# text_vectorization.get_vocabulary()[:10]\n\n# model = tf.keras.Sequential([\n#     text_vectorization,\n#     tf.keras.layers.Dense(100, activation=\"relu\"),\n#     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n# ])\n# model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n# model.fit(train_set, epochs=5, validation_data=valid_set)\n\n# Step 5: Compute mean embedding\ndef compute_mean_embedding(inputs):\n    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)\n    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n\ndatasets = tfds.load(name=\"imdb_reviews\")\ntrain_set = datasets[\"train\"]\nvalid_set = datasets[\"test\"]\ntrain_set = train_set.map(lambda x: (x[\"text\"], x[\"label\"]))\nvalid_set = valid_set.map(lambda x: (x[\"text\"], x[\"label\"]))\nembedding_size = 20\nbatch_size = 32\ntext_vectorization = tf.keras.layers.TextVectorization(max_tokens=max_tokens, output_mode=\"int\")\nsample_review = train_set.map(lambda text, label: text)\ntext_vectorization.adapt(sample_review)\nmodel = tf.keras.Sequential([\n    text_vectorization,\n    tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_size, mask_zero=True),\n    tf.keras.layers.Lambda(compute_mean_embedding),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\ntrain_set = train_set.shuffle(25000).batch(batch_size).prefetch(1)\nvalid_set = valid_set.batch(batch_size).prefetch(1)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\nmodel.fit(train_set, epochs=5, validation_data=valid_set)","block_group":"6274b267323d4233bfb2a96ed7eabd17","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-25.0.1\nCollecting tensorflow_datasets\n  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\nCollecting array_record>=0.5.0 (from tensorflow_datasets)\n  Downloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (877 bytes)\nCollecting dm-tree (from tensorflow_datasets)\n  Downloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nCollecting etils>=1.6.0 (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\nCollecting immutabledict (from tensorflow_datasets)\n  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: numpy in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.2)\nCollecting promise (from tensorflow_datasets)\n  Downloading promise-2.3.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.25.6)\nRequirement already satisfied: psutil in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (6.0.0)\nRequirement already satisfied: pyarrow in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from tensorflow_datasets) (17.0.0)\nRequirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\nCollecting simple_parsing (from tensorflow_datasets)\n  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\nCollecting tensorflow-metadata (from tensorflow_datasets)\n  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: termcolor in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\nCollecting toml (from tensorflow_datasets)\n  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\nRequirement already satisfied: wrapt in /root/venv/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.11/python3.10/kernel-libs/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2024.6.1)\nCollecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: typing_extensions in /root/venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.12.2)\nCollecting zipp (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting einops (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\nRequirement already satisfied: attrs>=18.2.0 in /root/venv/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\nRequirement already satisfied: six in /root/venv/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\nCollecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow_datasets)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\nCollecting protobuf>=3.20 (from tensorflow_datasets)\n  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\nDownloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading etils-1.12.2-py3-none-any.whl (167 kB)\nDownloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\nDownloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\nDownloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\nDownloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\nDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading einops-0.8.1-py3-none-any.whl (64 kB)\nDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\nDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\nBuilding wheels for collected packages: promise\n  Building wheel for promise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=10144d2622cc9d98184e1467a4aa6aece180d6f740b0268d9193e3e4a6af8420\n  Stored in directory: /root/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\nSuccessfully built promise\nInstalling collected packages: zipp, toml, protobuf, promise, importlib_resources, immutabledict, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, array_record, tensorflow_datasets\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.25.6\n    Uninstalling protobuf-4.25.6:\n      Successfully uninstalled protobuf-4.25.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngrpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed array_record-0.7.1 dm-tree-0.1.9 docstring-parser-0.16 einops-0.8.1 etils-1.12.2 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 protobuf-3.20.3 simple_parsing-0.1.7 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.8 toml-0.10.2 zipp-3.21.0\n2025-03-21 06:11:41.535411: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-21 06:11:41.567055: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-21 06:11:41.567184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-21 06:11:41.568270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-21 06:11:41.574327: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-21 06:11:41.575336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-03-21 06:11:42.712871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nWARNING:absl:Variant folder /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0 has no dataset_info.json\n/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\nDl Completed...: 0 url [00:00, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Size...:   0%|          | 0/80 [00:00<?, ? MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Size...:   5%|▌         | 4/80 [00:02<01:38,  1.30s/ MiB]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Size...:  16%|█▋        | 13/80 [00:03<00:27,  2.41 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Size...:  30%|███       | 24/80 [00:04<00:10,  5.12 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Size...:  45%|████▌     | 36/80 [00:05<00:06,  7.20 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Size...:  61%|██████▏   | 49/80 [00:06<00:03,  8.59 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Size...:  78%|███████▊  | 62/80 [00:07<00:01,  9.86 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Size...:  95%|█████████▌| 76/80 [00:08<00:00, 10.73 MiB/s]\u001b[A\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\nDl Completed...: 100%|██████████| 1/1 [00:08<00:00,  8.88s/ url]\nDl Size...: 100%|██████████| 80/80 [00:08<00:00,  9.01 MiB/s]\nDl Completed...: 100%|██████████| 1/1 [00:08<00:00,  8.88s/ url]\nGenerating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]\nGenerating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating train examples...: 1 examples [00:01,  1.95s/ examples]\u001b[A\nGenerating train examples...: 7445 examples [00:02, 3145.88 examples/s]\u001b[A\nGenerating train examples...: 14971 examples [00:03, 4794.65 examples/s]\u001b[A\nGenerating train examples...: 22458 examples [00:04, 5736.02 examples/s]\u001b[A\n                                                                        \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.9A7JPK_1.0.0/imdb_reviews-train.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  33%|███▎      | 1/3 [00:08<00:16,  8.43s/ splits]\nGenerating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating test examples...: 3101 examples [00:01, 3100.84 examples/s]\u001b[A\nGenerating test examples...: 9723 examples [00:02, 5171.46 examples/s]\u001b[A\nGenerating test examples...: 17098 examples [00:03, 6177.35 examples/s]\u001b[A\nGenerating test examples...: 24311 examples [00:04, 6586.09 examples/s]\u001b[A\n                                                                       \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.9A7JPK_1.0.0/imdb_reviews-test.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\nGenerating splits...:  67%|██████▋   | 2/3 [00:17<00:08,  8.64s/ splits]\nGenerating unsupervised examples...: 0 examples [00:00, ? examples/s]\u001b[A\nGenerating unsupervised examples...: 1 examples [00:03,  3.67s/ examples]\u001b[A\nGenerating unsupervised examples...: 7587 examples [00:04, 2127.32 examples/s]\u001b[A\nGenerating unsupervised examples...: 15308 examples [00:05, 3727.14 examples/s]\u001b[A\nGenerating unsupervised examples...: 23109 examples [00:06, 4908.77 examples/s]\u001b[A\nGenerating unsupervised examples...: 30918 examples [00:07, 5757.85 examples/s]\u001b[A\nGenerating unsupervised examples...: 38694 examples [00:08, 6352.93 examples/s]\u001b[A\nGenerating unsupervised examples...: 46509 examples [00:09, 6786.39 examples/s]\u001b[A\n                                                                               \u001b[A\nShuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.9A7JPK_1.0.0/imdb_reviews-unsupervised.tfrecord*...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\nEpoch 1/5\n782/782 [==============================] - 7s 8ms/step - loss: 0.4592 - accuracy: 0.7814 - val_loss: 0.3757 - val_accuracy: 0.8278\nEpoch 2/5\n782/782 [==============================] - 6s 7ms/step - loss: 0.3341 - accuracy: 0.8576 - val_loss: 0.3211 - val_accuracy: 0.8593\nEpoch 3/5\n782/782 [==============================] - 6s 7ms/step - loss: 0.3190 - accuracy: 0.8633 - val_loss: 0.3188 - val_accuracy: 0.8597\nEpoch 4/5\n782/782 [==============================] - 6s 7ms/step - loss: 0.3098 - accuracy: 0.8676 - val_loss: 0.3799 - val_accuracy: 0.8339\nEpoch 5/5\n782/782 [==============================] - 6s 7ms/step - loss: 0.3054 - accuracy: 0.8695 - val_loss: 0.3276 - val_accuracy: 0.8554\n","output_type":"stream"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"<keras.src.callbacks.History at 0x7f2c4071d240>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/293586b2-5181-475a-817b-7d5430fba8da","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=968d3c27-50e7-4d42-bdd9-442f6904c1c2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"01a53165867a4583ae9c201a8c1fcecf"}}